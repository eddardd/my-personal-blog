{
  
    
        "post0": {
            "title": "Deep Learning com Tensorflow",
            "content": ". import numpy as np import tensorflow as tf import matplotlib.pyplot as plt from sklearn.manifold import TSNE from skimage.transform import rotate from sklearn.metrics import accuracy_score from sklearn.preprocessing import OneHotEncoder # Estética dos plots plt.rcParams[&#39;mathtext.fontset&#39;] = &#39;custom&#39; plt.rcParams[&#39;mathtext.rm&#39;] = &#39;Bitstream Vera Sans&#39; plt.rcParams[&#39;mathtext.it&#39;] = &#39;Bitstream Vera Sans:italic&#39; plt.rcParams[&#39;mathtext.bf&#39;] = &#39;Bitstream Vera Sans:bold&#39; plt.rcParams[&#39;font.size&#39;] = 16 plt.rcParams[&#39;mathtext.fontset&#39;] = &#39;stix&#39; plt.rcParams[&#39;font.family&#39;] = &#39;STIXGeneral&#39; . Preprocessamento dos dados . Começamos por pre-processar os dados. Para tanto, utilisaremos o próprio Tensorflow para fazer o carregamento dos dados. À partir da biblioteca Keras, carregamos os dados de treino e de teste usando a chamada . tf.keras.datasets.mnist.load_data() . Na verdade, o Tensorflow possui vários datasets comuns em machine learning. Uma lista completa pode ser encontrada no seguinte link . (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() . Note que dividimos os dados em 4 arrays. Estes arrays correspondem aos dados de treino e teste. Os dados de treino correspondem àqueles que serão utilizados durante a otimização do modelo, e o de teste será usado para avaliar o modelo. Fazemos essa divisão por dois motivos: . Queremos simular a situação em que o nosso modelo é treinado num conjunto de dados fixo, e depois é utilisado na prática com dados novos, os quais o modelo não viu durante a fase de treino. Para o caso do MNIST, imagine que treinamos a rede numa base de dados local, e utilisamos o modelo para a predição em tempo real de dígitos numa aplicação remota. Os dados obtidos em tempo real não foram vistos pela rede neural durante treinamento. | As estatísticas obtidas com os dados de treinamento são geralmente mais otimistas do que em dados não vistos. Imagine o caso em que uma pessoa estuda para uma prova à partir de uma lista de exercícios. Quem você acha que teria o melhor desempenho? (1) um aluno que faz uma prova com as questões retiradas da lista, ou (2) um aluno que faz uma prova com questões inteiramente novas? | Além de dividir os dados em treino/teste, iremos também dividí-los entre características (array X) e rótulos (array y). . Formata&#231;&#227;o dos dados . Iremos começar analizando os dados como vieram no dataset da biblioteca tensorflow. Dado que as aplicações são, via de regra, para redes neurais convolucionais, os dados vem como matrizes. . Visualiza&#231;&#227;o imagens como matrizes . fig, ax = plt.subplots() ax.imshow(x_train[0], cmap=&#39;gray&#39;) _ = ax.set_xticks([]) _ = ax.set_yticks([]) print(&quot;Formato da matriz de dados: {}&quot;.format(x_train.shape)) . Formato da matriz de dados: (60000, 28, 28) . note que os dados estão salvos como imagens. Portanto, a faixa de valores para seus pixels está entre 0 e 255. Além disso, os rótulos estão salvos em formato categórico, ou seja, $y_{i} in {1, cdots, K }$, onde $K$ é o número de classes. Particularmente, $K = 10$ para o dataset MNIST. . Para converter a matriz de caracteríticas, tomaremos 2 passos: . converter de int para float, | converter da faixa [0, 255] para [0, 1] | Note que podemos aplicar a seguinte transformação, . $$ x leftarrow dfrac{x - x_{min}}{x_{max}-x_{min}}, $$Como discutido anteriormente, $x_{min} = 0$ e $x_{max} = 255$, portanto, . $$ x leftarrow dfrac{x}{255} $$Como nesse tutorial usaremos redes neurais convolucionais, as amostras permanecerão em formato de imagem. Dessa forma, temos tensores de treino/teste com formato $(N, H, W)$, onde $N_{tr} = 60000$, $H=28$ e $W=28$ . Exercício 1: Se um float ocupa 32 bits em memória, qual o espaço ocupado pelo tensor de treino? . Xtr = x_train.astype(float)[..., np.newaxis] / 255.0 Xts = x_test.astype(float)[..., np.newaxis] / 255.0 print(&quot;Formato da matriz de dados: {}&quot;.format(Xtr.shape)) print(&quot;Nova faixa de valores de X: [{}, {}]&quot;.format(Xtr.min(), Xtr.max())) . Formato da matriz de dados: (60000, 28, 28, 1) Nova faixa de valores de X: [0.0, 1.0] . Iremos também transformar a notação categórica dos rótulos na notação One Hot. Isso é simples utilizando a biblioteca scikit-learn do Python, através da classe OneHotEncoder. O exemplo abaixo fornece uma ilustração para 3 classes e 3 amostras: . $$ y^{cat} = [1, 2, 3] iff y^{OneHot} = begin{bmatrix} 1 &amp; 0 &amp; 0 0 &amp; 1 &amp; 0 0 &amp; 0 &amp; 1 end{bmatrix} $$ # OBS1: o objeto OneHotEncoder espera um array de 2 dimensões. # Porém y_train só possui 1 dimensão (observe os prints # abaixo). Para convertê-lo num array 2D, utilisaremos a # função reshape, que muda o formato do array. # OBS2: .reshape(-1, ...) faz com que a biblioteca numpy faça # uma inferência do valor adequado para a dimensão especificada # como -1. No caso, como utilisamos .reshape(-1, 1), teremos uma # transformação de formatação (N, ) -&gt; (N, 1) print(&quot;Formato de y_train antes de usar .reshape: {}&quot;.format(y_train.shape)) print(&quot;Formato de y_train após usar .reshape: {}&quot;.format(y_train.reshape(-1, 1).shape)) enc = OneHotEncoder(sparse=False) ytr = enc.fit_transform(y_train.reshape(-1, 1)) yts = enc.fit_transform(y_test.reshape(-1, 1)) print(&quot;Formato da matriz de rótulos após a aplicação da nova codificação: {}&quot;.format(ytr.shape)) . Formato de y_train antes de usar .reshape: (60000,) Formato de y_train após usar .reshape: (60000, 1) Formato da matriz de rótulos após a aplicação da nova codificação: (60000, 10) . Defini&#231;&#227;o dos modelos . def network1(input_shape=(28, 28, 1), n_classes=10): x = tf.keras.layers.Input(shape=input_shape) # Convolutional block: Convolution -&gt; Activation -&gt; Pooling y = tf.keras.layers.Conv2D(filters=36, kernel_size=(3, 3), padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) y = tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=&#39;same&#39;)(y) y = tf.keras.layers.Flatten()(y) y = tf.keras.layers.Dense(units=100, activation=&#39;relu&#39;)(y) y = tf.keras.layers.Dense(units=n_classes, activation=&#39;softmax&#39;)(y) return tf.keras.models.Model(x, y) . def network2(input_shape=(28, 28, 1), n_classes=10): x = tf.keras.layers.Input(shape=input_shape) # Convolutional block: Convolution -&gt; Activation -&gt; Pooling y = tf.keras.layers.Conv2D(filters=36, kernel_size=(7, 7), padding=&#39;same&#39;, kernel_regularizer=tf.keras.regularizers.l2(1e-3), activation=&#39;relu&#39;)(x) y = tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=&#39;same&#39;)(y) y = tf.keras.layers.Flatten()(y) y = tf.keras.layers.Dense(units=100, activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(y) y = tf.keras.layers.Dense(units=n_classes, activation=&#39;softmax&#39;)(y) return tf.keras.models.Model(x, y) . Treinamento do modelo n&#227;o-regularizado . model1 = network1() model1.summary() . Model: &#34;functional_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 28, 28, 1)] 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 36) 360 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 14, 14, 36) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 7056) 0 _________________________________________________________________ dense_2 (Dense) (None, 100) 705700 _________________________________________________________________ dense_3 (Dense) (None, 10) 1010 ================================================================= Total params: 707,070 Trainable params: 707,070 Non-trainable params: 0 _________________________________________________________________ . loss_obj = tf.keras.losses.CategoricalCrossentropy() optimizer_obj = tf.keras.optimizers.Adam(lr=0.01) model1.compile(loss=loss_obj, optimizer=optimizer_obj, metrics=[&#39;accuracy&#39;]) . hist1 = model1.fit(x=Xtr, y=ytr, batch_size=1024, epochs=30, validation_data=(Xts, yts), validation_batch_size=128) . Epoch 1/30 59/59 [==============================] - 1s 21ms/step - loss: 0.3896 - accuracy: 0.8817 - val_loss: 0.0785 - val_accuracy: 0.9752 Epoch 2/30 59/59 [==============================] - 1s 18ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.0575 - val_accuracy: 0.9812 Epoch 3/30 59/59 [==============================] - 1s 18ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.0549 - val_accuracy: 0.9833 Epoch 4/30 59/59 [==============================] - 1s 18ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 0.0477 - val_accuracy: 0.9852 Epoch 5/30 59/59 [==============================] - 1s 18ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0555 - val_accuracy: 0.9835 Epoch 6/30 59/59 [==============================] - 1s 18ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0529 - val_accuracy: 0.9841 Epoch 7/30 29/59 [=============&gt;................] - ETA: 0s - loss: 0.0095 - accuracy: 0.9974 . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-23-8fc2a4d20239&gt; in &lt;module&gt;() -&gt; 1 hist1 = model1.fit(x=Xtr, y=ytr, batch_size=1024, epochs=30, validation_data=(Xts, yts), validation_batch_size=128) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs) 106 def _method_wrapper(self, *args, **kwargs): 107 if not self._in_multi_worker_mode(): # pylint: disable=protected-access --&gt; 108 return method(self, *args, **kwargs) 109 110 # Running inside `run_distribute_coordinator` already. /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) 1101 logs = tmp_logs # No error, now safe to assign to logs. 1102 end_step = step + data_handler.step_increment -&gt; 1103 callbacks.on_train_batch_end(end_step, logs) 1104 epoch_logs = copy.copy(logs) 1105 /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs) 438 &#34;&#34;&#34; 439 if self._should_call_train_batch_hooks: --&gt; 440 self._call_batch_hook(ModeKeys.TRAIN, &#39;end&#39;, batch, logs=logs) 441 442 def on_test_batch_begin(self, batch, logs=None): /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs) 287 self._call_batch_begin_hook(mode, batch, logs) 288 elif hook == &#39;end&#39;: --&gt; 289 self._call_batch_end_hook(mode, batch, logs) 290 else: 291 raise ValueError(&#39;Unrecognized hook: {}&#39;.format(hook)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs) 307 batch_time = time.time() - self._batch_start_time 308 --&gt; 309 self._call_batch_hook_helper(hook_name, batch, logs) 310 311 if self._check_timing: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs) 340 hook = getattr(callback, hook_name) 341 if getattr(callback, &#39;_supports_tf_logs&#39;, False): --&gt; 342 hook(batch, logs) 343 else: 344 if numpy_logs is None: # Only convert once. /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs) 959 960 def on_train_batch_end(self, batch, logs=None): --&gt; 961 self._batch_update_progbar(batch, logs) 962 963 def on_test_batch_end(self, batch, logs=None): /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _batch_update_progbar(self, batch, logs) 1014 if self.verbose == 1: 1015 # Only block async when verbose = 1. -&gt; 1016 logs = tf_utils.to_numpy_or_python_type(logs) 1017 self.progbar.update(self.seen, list(logs.items()), finalize=False) 1018 /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in to_numpy_or_python_type(tensors) 535 return t # Don&#39;t turn ragged or sparse tensors to NumPy. 536 --&gt; 537 return nest.map_structure(_to_single_numpy_or_python_type, tensors) 538 539 /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs) 633 634 return pack_sequence_as( --&gt; 635 structure[0], [func(*x) for x in entries], 636 expand_composites=expand_composites) 637 /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in &lt;listcomp&gt;(.0) 633 634 return pack_sequence_as( --&gt; 635 structure[0], [func(*x) for x in entries], 636 expand_composites=expand_composites) 637 /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t) 531 def _to_single_numpy_or_python_type(t): 532 if isinstance(t, ops.Tensor): --&gt; 533 x = t.numpy() 534 return x.item() if np.ndim(x) == 0 else x 535 return t # Don&#39;t turn ragged or sparse tensors to NumPy. /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self) 1061 &#34;&#34;&#34; 1062 # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors. -&gt; 1063 maybe_arr = self._numpy() # pylint: disable=protected-access 1064 return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr 1065 /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self) 1027 def _numpy(self): 1028 try: -&gt; 1029 return self._numpy_internal() 1030 except core._NotOkStatusException as e: # pylint: disable=protected-access 1031 six.raise_from(core._status_to_exception(e.code, e.message), None) # pylint: disable=protected-access KeyboardInterrupt: . . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist1.history[&#39;accuracy&#39;]), label=&#39;Treino&#39;) axes[0].plot(100 * np.array(hist1.history[&#39;val_accuracy&#39;]), label=&#39;Teste&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist1.history[&#39;loss&#39;]), label=&#39;Treino&#39;) axes[1].plot(100 * np.array(hist1.history[&#39;val_loss&#39;]), label=&#39;Teste&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7ff4fddc3128&gt; . filters = model1.weights[0].numpy() fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(filters[:, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . inp = model1.layers[0].input outs = [layer.output for layer in model1.layers] layerized_model1 = tf.keras.models.Model(inp, outs) Omat = layerized_model1.predict(Xts[0, ...].reshape(1, 28, 28, 1)) . plt.imshow(Omat[0][0, :, :, 0], cmap=&#39;gray&#39;) plt.yticks([]) plt.xticks([]) . ([], &lt;a list of 0 Text major ticklabel objects&gt;) . fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(Omat[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(Omat[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].bar(np.arange(10), Omat[-1][0, :]) _ = axes[1].set_xticks([i for i in range(10)]) . x = Omat[0][0, :, :, 0] xrot = rotate(x, angle=15) fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].imshow(xrot, cmap=&#39;gray&#39;) axes[1].set_xticks([]) axes[1].set_yticks([]) . [] . tmp = layerized_model.predict(xrot.reshape(1, 28, 28, 1)) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(2, 2, figsize=(10, 5)) axes[0, 0].imshow(x, cmap=&#39;gray&#39;) axes[0, 0].set_xticks([]) axes[0, 0].set_yticks([]) axes[0, 1].imshow(xrot, cmap=&#39;gray&#39;) axes[0, 1].set_xticks([]) axes[0, 1].set_yticks([]) axes[1, 0].bar(np.arange(10), Omat[-1][0, :]) axes[1, 1].bar(np.arange(10), tmp[-1][0, :]) . &lt;BarContainer object of 10 artists&gt; . x = Omat[0][0, :, :, 0] xrot = rotate(x, angle=45) fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].imshow(xrot, cmap=&#39;gray&#39;) axes[1].set_xticks([]) axes[1].set_yticks([]) . [] . tmp = layerized_model1.predict(xrot.reshape(1, 28, 28, 1)) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(2, 2, figsize=(10, 5)) axes[0, 0].imshow(x, cmap=&#39;gray&#39;) axes[0, 0].set_xticks([]) axes[0, 0].set_yticks([]) axes[0, 1].imshow(xrot, cmap=&#39;gray&#39;) axes[0, 1].set_xticks([]) axes[0, 1].set_yticks([]) axes[1, 0].bar(np.arange(10), Omat[-1][0, :]) axes[1, 0].set_ylim([0, 1.1]) _ = axes[1, 0].set_xticks([i for i in range(0, 10)]) axes[1, 1].bar(np.arange(10), tmp[-1][0, :]) axes[1, 1].set_ylim([0, 1.1]) _ = axes[1, 1].set_xticks([i for i in range(0, 10)]) . x = Omat[0][0, :, :, 0] noise = 0.5 * np.random.randn(*x.shape) xnoise = np.clip(x + noise, 0.0, 1.0) fig, axes = plt.subplots(1, 3, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].imshow(xnoise, cmap=&#39;gray&#39;) axes[1].set_xticks([]) axes[1].set_yticks([]) axes[2].imshow(noise, cmap=&#39;gray&#39;) axes[2].set_xticks([]) axes[2].set_yticks([]) . [] . tmp = layerized_model1.predict(xnoise.reshape(1, 28, 28, 1)) . fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(2, 2, figsize=(10, 5)) axes[0, 0].imshow(x, cmap=&#39;gray&#39;) axes[0, 0].set_xticks([]) axes[0, 0].set_yticks([]) axes[0, 1].imshow(xnoise, cmap=&#39;gray&#39;) axes[0, 1].set_xticks([]) axes[0, 1].set_yticks([]) axes[1, 0].bar(np.arange(10), Omat[-1][0, :]) axes[1, 0].set_ylim([0, 1.1]) _ = axes[1, 0].set_xticks([i for i in range(0, 10)]) axes[1, 1].bar(np.arange(10), tmp[-1][0, :]) axes[1, 1].set_ylim([0, 1.1]) _ = axes[1, 1].set_xticks([i for i in range(0, 10)]) . y = Xts[1, ...].reshape(28, 28) alpha = 0.25 interpol_xy = np.clip((1 - alpha) * x + alpha * y, 0.0, 1.0) fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].imshow(interpol_xy, cmap=&#39;gray&#39;) axes[1].set_xticks([]) axes[1].set_yticks([]) . [] . tmp = layerized_model1.predict(interpol_xy.reshape(1, 28, 28, 1)) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(tmp[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(2, 2, figsize=(10, 5)) axes[0, 0].imshow(x, cmap=&#39;gray&#39;) axes[0, 0].set_xticks([]) axes[0, 0].set_yticks([]) axes[0, 1].imshow(interpol_xy, cmap=&#39;gray&#39;) axes[0, 1].set_xticks([]) axes[0, 1].set_yticks([]) axes[1, 0].bar(np.arange(10), Omat[-1][0, :]) axes[1, 0].set_ylim([0, 1.1]) _ = axes[1, 0].set_xticks([i for i in range(0, 10)]) axes[1, 1].bar(np.arange(10), tmp[-1][0, :]) axes[1, 1].set_ylim([0, 1.1]) _ = axes[1, 1].set_xticks([i for i in range(0, 10)]) . Treinamento do modelo regularizado . model2 = network2() model2.summary() . Model: &#34;functional_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 28, 28, 1)] 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 36) 1800 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 14, 14, 36) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 7056) 0 _________________________________________________________________ dense_2 (Dense) (None, 100) 705700 _________________________________________________________________ dense_3 (Dense) (None, 10) 1010 ================================================================= Total params: 708,510 Trainable params: 708,510 Non-trainable params: 0 _________________________________________________________________ . loss_obj = tf.keras.losses.CategoricalCrossentropy() optimizer_obj = tf.keras.optimizers.Adam(lr=0.01) model2.compile(loss=loss_obj, optimizer=optimizer_obj, metrics=[&#39;accuracy&#39;]) . hist2 = model2.fit(x=Xtr, y=ytr, batch_size=1024, epochs=30, validation_data=(Xts, yts), validation_batch_size=128) . Epoch 1/30 59/59 [==============================] - 1s 22ms/step - loss: 0.6784 - accuracy: 0.8953 - val_loss: 0.2166 - val_accuracy: 0.9735 Epoch 2/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1922 - accuracy: 0.9717 - val_loss: 0.1650 - val_accuracy: 0.9763 Epoch 3/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1672 - accuracy: 0.9746 - val_loss: 0.1539 - val_accuracy: 0.9772 Epoch 4/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1580 - accuracy: 0.9770 - val_loss: 0.1367 - val_accuracy: 0.9819 Epoch 5/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1517 - accuracy: 0.9775 - val_loss: 0.1408 - val_accuracy: 0.9799 Epoch 6/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1460 - accuracy: 0.9791 - val_loss: 0.1364 - val_accuracy: 0.9827 Epoch 7/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1401 - accuracy: 0.9804 - val_loss: 0.1364 - val_accuracy: 0.9778 Epoch 8/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1428 - accuracy: 0.9794 - val_loss: 0.1384 - val_accuracy: 0.9777 Epoch 9/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1334 - accuracy: 0.9815 - val_loss: 0.1343 - val_accuracy: 0.9805 Epoch 10/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1312 - accuracy: 0.9815 - val_loss: 0.1217 - val_accuracy: 0.9823 Epoch 11/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1380 - accuracy: 0.9801 - val_loss: 0.1439 - val_accuracy: 0.9765 Epoch 12/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1320 - accuracy: 0.9817 - val_loss: 0.1237 - val_accuracy: 0.9818 Epoch 13/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1326 - accuracy: 0.9808 - val_loss: 0.1493 - val_accuracy: 0.9763 Epoch 14/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1283 - accuracy: 0.9819 - val_loss: 0.1145 - val_accuracy: 0.9840 Epoch 15/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1305 - accuracy: 0.9812 - val_loss: 0.1307 - val_accuracy: 0.9805 Epoch 16/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1255 - accuracy: 0.9827 - val_loss: 0.1200 - val_accuracy: 0.9832 Epoch 17/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1242 - accuracy: 0.9823 - val_loss: 0.1394 - val_accuracy: 0.9755 Epoch 18/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1242 - accuracy: 0.9825 - val_loss: 0.1146 - val_accuracy: 0.9857 Epoch 19/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1223 - accuracy: 0.9827 - val_loss: 0.1157 - val_accuracy: 0.9829 Epoch 20/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1233 - accuracy: 0.9825 - val_loss: 0.1206 - val_accuracy: 0.9837 Epoch 21/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1189 - accuracy: 0.9840 - val_loss: 0.1135 - val_accuracy: 0.9849 Epoch 22/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1234 - accuracy: 0.9819 - val_loss: 0.1268 - val_accuracy: 0.9810 Epoch 23/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1202 - accuracy: 0.9830 - val_loss: 0.1265 - val_accuracy: 0.9802 Epoch 24/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1194 - accuracy: 0.9830 - val_loss: 0.1245 - val_accuracy: 0.9803 Epoch 25/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1224 - accuracy: 0.9825 - val_loss: 0.1144 - val_accuracy: 0.9826 Epoch 26/30 59/59 [==============================] - 1s 18ms/step - loss: 0.1149 - accuracy: 0.9842 - val_loss: 0.1087 - val_accuracy: 0.9829 Epoch 27/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1193 - accuracy: 0.9827 - val_loss: 0.1279 - val_accuracy: 0.9803 Epoch 28/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1157 - accuracy: 0.9837 - val_loss: 0.1053 - val_accuracy: 0.9868 Epoch 29/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1167 - accuracy: 0.9826 - val_loss: 0.1192 - val_accuracy: 0.9820 Epoch 30/30 59/59 [==============================] - 1s 19ms/step - loss: 0.1134 - accuracy: 0.9840 - val_loss: 0.1102 - val_accuracy: 0.9831 . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist2.history[&#39;accuracy&#39;]), label=&#39;Treino&#39;) axes[0].plot(100 * np.array(hist2.history[&#39;val_accuracy&#39;]), label=&#39;Teste&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist2.history[&#39;loss&#39;]), label=&#39;Treino&#39;) axes[1].plot(100 * np.array(hist2.history[&#39;val_loss&#39;]), label=&#39;Teste&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7ff4fd196940&gt; . filters = model2.weights[0].numpy() fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(filters[:, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . inp = model2.layers[0].input outs = [layer.output for layer in model2.layers] layerized_model2 = tf.keras.models.Model(inp, outs) Omat = layerized_model2.predict(Xts[0, ...].reshape(1, 28, 28, 1)) . plt.imshow(Omat[0][0, :, :, 0], cmap=&#39;gray&#39;) plt.yticks([]) plt.xticks([]) . ([], &lt;a list of 0 Text major ticklabel objects&gt;) . fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(Omat[1][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) fig, axes = plt.subplots(6, 6, figsize=(8, 8)) for i, ax in enumerate(axes.flatten()): ax.imshow(np.squeeze(Omat[2][0, :, :, i]), cmap=&#39;gray&#39;) ax.set_yticks([]) ax.set_xticks([]) . fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].imshow(x, cmap=&#39;gray&#39;) axes[0].set_xticks([]) axes[0].set_yticks([]) axes[1].bar(np.arange(10), Omat[-1][0, :]) _ = axes[1].set_xticks([i for i in range(10)]) . Compara&#231;&#227;o entre os dois modelos . Acur&#225;cia . fig, axes = plt.subplots(2, 1, figsize=(15, 5)) axes[0].plot(hist1.history[&#39;accuracy&#39;], label=&#39;Modelo 1&#39;) axes[0].plot(hist2.history[&#39;accuracy&#39;], label=&#39;Modelo 2&#39;) axes[0].legend() axes[1].plot(hist1.history[&#39;val_accuracy&#39;], label=&#39;Modelo 1&#39;) axes[1].plot(hist2.history[&#39;val_accuracy&#39;], label=&#39;Modelo 2&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7ff4fd14d198&gt; . Custo . fig, axes = plt.subplots(2, 1, figsize=(15, 5)) axes[0].plot(hist1.history[&#39;loss&#39;], label=&#39;Modelo 1&#39;) axes[0].plot(hist2.history[&#39;loss&#39;], label=&#39;Modelo 2&#39;) axes[0].legend() axes[1].plot(hist1.history[&#39;val_loss&#39;], label=&#39;Modelo 1&#39;) axes[1].plot(hist2.history[&#39;val_loss&#39;], label=&#39;Modelo 2&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7ff4fd15be48&gt; . M&#233;tricas . yp1 = model1.predict(Xts).argmax(axis=1) yp2 = model2.predict(Xts).argmax(axis=1) . print(&quot;Taxa de precisão: {}&quot;.format(100 * accuracy_score(y_test, yp1))) print(&quot;Taxa de precisão (Regularizado): {}&quot;.format(100 * accuracy_score(y_test, yp2))) . Taxa de precisão: 98.98 Taxa de precisão (Regularizado): 98.31 . Visualiza&#231;&#227;o das representa&#231;&#245;es . Omat = layerized_model2.predict(Xts) . sample_inds = [] for i in np.unique(y_test): sample_inds.append(np.where(y_test == i)[0][:100]) sample_inds = np.concatenate(sample_inds, axis=0) . raw_rep = Omat[0][sample_inds, :] print(raw_rep.shape) tsne = TSNE(n_components=2, init=&#39;pca&#39;, verbose=True) tsne.fit(raw_rep.reshape(-1, 784)) embedding = tsne.embedding_ . (1000, 28, 28, 1) [t-SNE] Computing 91 nearest neighbors... [t-SNE] Indexed 1000 samples in 0.056s... [t-SNE] Computed neighbors for 1000 samples in 1.707s... [t-SNE] Computed conditional probabilities for sample 1000 / 1000 [t-SNE] Mean sigma: 2.611868 [t-SNE] KL divergence after 250 iterations with early exaggeration: 70.110123 [t-SNE] KL divergence after 1000 iterations: 1.031477 . fig, ax = plt.subplots(1, 1, figsize=(8, 8)) for i in np.unique(y_test): ax.scatter(embedding[100 * i: 100 * (i + 1), 0], embedding[100 * i: 100 * (i + 1), 1], label=&#39;Digit {}&#39;.format(i)) ax.legend(loc=&#39;upper right&#39;, bbox_to_anchor=(1.3, 1.0)) . &lt;matplotlib.legend.Legend at 0x7ff4fc52c6d8&gt; . conv_rep = Omat[3][sample_inds, :] print(conv_rep.shape) tsne = TSNE(n_components=2, init=&#39;pca&#39;, verbose=True) tsne.fit(conv_rep) embedding = tsne.embedding_ . [t-SNE] Computing 91 nearest neighbors... [t-SNE] Indexed 1000 samples in 0.508s... [t-SNE] Computed neighbors for 1000 samples in 15.771s... [t-SNE] Computed conditional probabilities for sample 1000 / 1000 [t-SNE] Mean sigma: 2.780777 [t-SNE] KL divergence after 250 iterations with early exaggeration: 71.441025 [t-SNE] KL divergence after 1000 iterations: 0.994165 . fig, ax = plt.subplots(1, 1, figsize=(8, 8)) for i in np.unique(y_test): ax.scatter(embedding[100 * i: 100 * (i + 1), 0], embedding[100 * i: 100 * (i + 1), 1], label=&#39;Digit {}&#39;.format(i)) ax.legend(loc=&#39;upper right&#39;, bbox_to_anchor=(1.3, 1.0)) . &lt;matplotlib.legend.Legend at 0x7ff4fdece5f8&gt; . dense_rep = Omat[-2][sample_inds, :] tsne = TSNE(n_components=2, init=&#39;pca&#39;, verbose=True) tsne.fit(dense_rep) embedding = tsne.embedding_ . [t-SNE] Computing 91 nearest neighbors... [t-SNE] Indexed 1000 samples in 0.007s... [t-SNE] Computed neighbors for 1000 samples in 0.217s... [t-SNE] Computed conditional probabilities for sample 1000 / 1000 [t-SNE] Mean sigma: 1.311268 [t-SNE] KL divergence after 250 iterations with early exaggeration: 54.055824 [t-SNE] KL divergence after 1000 iterations: 0.571683 . fig, ax = plt.subplots(1, 1, figsize=(8, 8)) for i in np.unique(y_test): ax.scatter(embedding[100 * i: 100 * (i + 1), 0], embedding[100 * i: 100 * (i + 1), 1], label=&#39;Digit {}&#39;.format(i)) ax.legend(loc=&#39;upper right&#39;, bbox_to_anchor=(1.3, 1.0)) . &lt;matplotlib.legend.Legend at 0x7ff4fdea9c88&gt; .",
            "url": "https://eddardd.github.io/my-personal-blog/deep%20learning/tensorflow/image%20classification/neural%20networks/2020/12/01/Deep-Learning-com-Tensorflow-Aula2.html",
            "relUrl": "/deep%20learning/tensorflow/image%20classification/neural%20networks/2020/12/01/Deep-Learning-com-Tensorflow-Aula2.html",
            "date": " • Dec 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Deep Learning com Tensorflow",
            "content": ". import numpy as np import tensorflow as tf import matplotlib.pyplot as plt from sklearn.metrics import accuracy_score from sklearn.preprocessing import OneHotEncoder # Estética dos plots plt.rcParams[&#39;mathtext.fontset&#39;] = &#39;custom&#39; plt.rcParams[&#39;mathtext.rm&#39;] = &#39;Bitstream Vera Sans&#39; plt.rcParams[&#39;mathtext.it&#39;] = &#39;Bitstream Vera Sans:italic&#39; plt.rcParams[&#39;mathtext.bf&#39;] = &#39;Bitstream Vera Sans:bold&#39; plt.rcParams[&#39;font.size&#39;] = 16 plt.rcParams[&#39;mathtext.fontset&#39;] = &#39;stix&#39; plt.rcParams[&#39;font.family&#39;] = &#39;STIXGeneral&#39; . Preprocessamento dos dados . Começamos por pre-processar os dados. Para tanto, utilisaremos o próprio Tensorflow para fazer o carregamento dos dados. À partir da biblioteca Keras, carregamos os dados de treino e de teste usando a chamada . tf.keras.datasets.mnist.load_data() . Na verdade, o Tensorflow possui vários datasets comuns em machine learning. Uma lista completa pode ser encontrada no seguinte link . (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11493376/11490434 [==============================] - 0s 0us/step . Note que dividimos os dados em 4 arrays. Estes arrays correspondem aos dados de treino e teste. Os dados de treino correspondem àqueles que serão utilizados durante a otimização do modelo, e o de teste será usado para avaliar o modelo. Fazemos essa divisão por dois motivos: . Queremos simular a situação em que o nosso modelo é treinado num conjunto de dados fixo, e depois é utilisado na prática com dados novos, os quais o modelo não viu durante a fase de treino. Para o caso do MNIST, imagine que treinamos a rede numa base de dados local, e utilisamos o modelo para a predição em tempo real de dígitos numa aplicação remota. Os dados obtidos em tempo real não foram vistos pela rede neural durante treinamento. | As estatísticas obtidas com os dados de treinamento são geralmente mais otimistas do que em dados não vistos. Imagine o caso em que uma pessoa estuda para uma prova à partir de uma lista de exercícios. Quem você acha que teria o melhor desempenho? (1) um aluno que faz uma prova com as questões retiradas da lista, ou (2) um aluno que faz uma prova com questões inteiramente novas? | Além de dividir os dados em treino/teste, iremos também dividí-los entre características (array X) e rótulos (array y). . Formata&#231;&#227;o dos dados . Iremos começar analizando os dados como vieram no dataset da biblioteca tensorflow. Dado que as aplicações são, via de regra, para redes neurais convolucionais, os dados vem como matrizes. . Visualiza&#231;&#227;o imagens como matrizes . fig, ax = plt.subplots() ax.imshow(x_train[0], cmap=&#39;gray&#39;) _ = ax.set_xticks([]) _ = ax.set_yticks([]) print(&quot;Formato da matriz de dados: {}&quot;.format(x_train.shape)) . Formato da matriz de dados: (60000, 28, 28) . note que os dados estão salvos como imagens. Portanto, a faixa de valores para seus pixels está entre 0 e 255. Além disso, os rótulos estão salvos em formato categórico, ou seja, $y_{i} in {1, cdots, K }$, onde $K$ é o número de classes. Particularmente, $K = 10$ para o dataset MNIST. . print(&quot;Faixa de valores de X: [{}, {}]&quot;.format(x_train.min(), x_train.max())) print(&quot;Tipos de dados das matrizes: X {}, y {}&quot;.format(x_train.dtype, x_test.dtype)) print(&quot;Codificação dos rótulos: {}&quot;.format(y_train[0])) . Faixa de valores de X: [0, 255] Tipos de dados das matrizes: X uint8, y uint8 Codificação dos rótulos: 5 . Para converter a matriz de caracteríticas, tomaremos 2 passos: . converter de int para float, | converter da faixa [0, 255] para [0, 1] | Note que podemos aplicar a seguinte transformação, . $$ x leftarrow dfrac{x - x_{min}}{x_{max}-x_{min}}, $$Como discutido anteriormente, $x_{min} = 0$ e $x_{max} = 255$, portanto, . $$ x leftarrow dfrac{x}{255} $$ Xtr = x_train.astype(float) / 255.0 Xts = x_test.astype(float) / 255.0 print(&quot;Nova faixa de valores de X: [{}, {}]&quot;.format(Xtr.min(), Xtr.max())) . Nova faixa de valores de X: [0.0, 1.0] . Precisamos ainda transformar o formato dos dados. Para tanto, queremos converter cada imagem-matriz em imagem-vetor através da notação Row-Major. Isso é particularmente simples em Python. Utilizamos o método $.reshape$ da classe $ndarray$, . # OBS: o uso de -1 numa das dimensões do reshape faz com que numpy infira o valor # da dada dimensão. Xtr = Xtr.reshape(-1, 28 * 28) Xts = Xts.reshape(-1, 28 * 28) print(&quot;Novo formato de X: {}&quot;.format(Xtr.shape)) . Novo formato de X: (60000, 784) . Além disso, iremos também transformar a notação categórica dos rótulos na notação One Hot. Isso é simples utilizando a biblioteca scikit-learn do Python, através da classe OneHotEncoder. O exemplo abaixo fornece uma ilustração para 3 classes e 3 amostras: . $$ y^{cat} = [1, 2, 3] iff y^{OneHot} = begin{bmatrix} 1 &amp; 0 &amp; 0 0 &amp; 1 &amp; 0 0 &amp; 0 &amp; 1 end{bmatrix} $$ # OBS1: o objeto OneHotEncoder espera um array de 2 dimensões. # Porém y_train só possui 1 dimensão (observe os prints # abaixo). Para convertê-lo num array 2D, utilisaremos a # função reshape, que muda o formato do array. # OBS2: .reshape(-1, ...) faz com que a biblioteca numpy faça # uma inferência do valor adequado para a dimensão especificada # como -1. No caso, como utilisamos .reshape(-1, 1), teremos uma # transformação de formatação (N, ) -&gt; (N, 1) print(&quot;Formato de y_train antes de usar .reshape: {}&quot;.format(y_train.shape)) print(&quot;Formato de y_train após usar .reshape: {}&quot;.format(y_train.reshape(-1, 1).shape)) enc = OneHotEncoder(sparse=False) ytr = enc.fit_transform(y_train.reshape(-1, 1)) yts = enc.fit_transform(y_test.reshape(-1, 1)) print(&quot;Formato da matriz de rótulos após a aplicação da nova codificação: {}&quot;.format(ytr.shape)) . Formato de y_train antes de usar .reshape: (60000,) Formato de y_train após usar .reshape: (60000, 1) Formato da matriz de rótulos após a aplicação da nova codificação: (60000, 10) . Treinamento Perceptron Simples . Aqui treinaremos uma rede Perceptron simples com uma camada. Para tanto, utilisaremos as seguintes classes da biblioteca Keras, . Keras Layers Input Layer | Dense Layer | . | Keras Model | . Defini&#231;&#227;o da rede . Aqui, temos apenas 2 camadas: a camada de entrada, que recebe uma matriz $(N, d)$, onde $N$ é o número de amostras e $d$ é o número de características. . Temos uma segunda camada, chamada de camada de output, que toma como entrada o o objeto simbólico de ouptut da camada de entrada, e tem como saída o objeto simbólico . $$ mathbf{y} = varphi( mathbf{Wx} + mathbf{b}). $$Iremos portanto por estes conceitos dentro de uma função, que irá ter como saída um objeto $tf.keras.models.Model$. . def perceptron_mnist(input_shape=(784,), n_classes=10): x = tf.keras.layers.Input(shape=input_shape) y = tf.keras.layers.Dense(units=n_classes, activation=&#39;sigmoid&#39;)(x) return tf.keras.models.Model(x, y) . model1 = perceptron_mnist() # Print do modelo construído model1.summary() . Model: &#34;functional_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense (Dense) (None, 10) 7850 ================================================================= Total params: 7,850 Trainable params: 7,850 Non-trainable params: 0 _________________________________________________________________ . Compila&#231;&#227;o do modelo . Para compilar o modelo, precisaremos definir: . Funções de Custo | Otimizadores | em especial, iremos utilisar o erro quadrático médio, definido por, . $$ mathcal{L}( mathbf{W}, mathbf{b}) = dfrac{1}{2N}|| mathbf{y} - hat{ mathbf{y}}||_{2}^{2}, mathcal{L}( mathbf{W}, mathbf{b}) = dfrac{1}{2N} sum_{i=1}^{N}( mathbf{y}_{i} - varphi( mathbf{Wx}_{i} + mathbf{b}))^{2} $$e definiremos o otimizador Stochastic Gradient Descent (SGD), que atualizará os parâmetros da rede neural através da regra: . $$ mathbf{W}^{ ell + 1} leftarrow mathbf{W}^{ ell} - eta dfrac{ partial mathcal{L}}{ partial mathbf{W}}, mathbf{b}^{ ell + 1} leftarrow mathbf{b}^{ ell} - eta dfrac{ partial mathcal{L}}{ partial mathbf{b}}. $$onde $ eta$ é um parâmetro escolhido previamente, que define quão longo é o passo de otimização tomado na direção do gradiente. No contexto de machine learning, $ eta$ é chamado de Learning Rate. . O que faz a compilação do modelo? A compilação de um modelo Keras faz o seguinte: . Para cada operação no grafo computacional (construído anteriormente pela função que define o modelo), calcula os gradientes. | Define a regra para a atualização dos parâmetros | Inicializa cada variável no modelo. | Basicamente a compilação prepara o modelo para duas tarefas: inferência (feed-forward) e aprendizado (backpropagation). . # Passo à passo: # 1. Instancie a função de custo (num primeiro momento, use MeanSquaredError) # 2. Instancie o otimizador (SGD, ou Stochastic Gradient Descent) # 3. Compile o modelo. # 1. Instanciação do custo loss_obj = tf.keras.losses.MeanSquaredError() # 2. Instanciação do otimizador optimizer_obj = tf.keras.optimizers.SGD(learning_rate=1e-1) # 3. Compilação do modelo model1.compile( loss=loss_obj, optimizer=optimizer_obj, metrics=[&#39;accuracy&#39;] ) . Uma vez que o modelo foi compilado, podemos lançar seu aprendizado. fazemos isso com a função .fit. Em especial, definiremos, . A matriz de treino (caracteríticas), x, que em nossa notação é Xtr, | A matriz de treino (rótulos), y, que em nossa notação é ytr, | O tamanho dos minibatches, _batch_size_, que definiremos como 1024, | O número de épocas, _n_epochs_, que definiremos como 150, | Os dados de validação, _validation_data_, que na nossa notação é a dupla $(Xtr, ytr)$, | O _batch_size_ dos dados de validação, que utilisaremos 128. | Podemos ainda salvar o histórico de treinamento, que contém um dicionário com várias métricas por época de treinamento. . hist1 = model1.fit(x=Xtr, y=ytr, batch_size=1024, epochs=150, validation_data=(Xts, yts), validation_batch_size=128) . Epoch 1/150 59/59 [==============================] - 1s 9ms/step - loss: 0.1384 - accuracy: 0.1834 - val_loss: 0.0972 - val_accuracy: 0.2847 Epoch 2/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.3376 - val_loss: 0.0872 - val_accuracy: 0.4022 Epoch 3/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0854 - accuracy: 0.4326 - val_loss: 0.0825 - val_accuracy: 0.4715 Epoch 4/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.4882 - val_loss: 0.0786 - val_accuracy: 0.5175 Epoch 5/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.5295 - val_loss: 0.0751 - val_accuracy: 0.5493 Epoch 6/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.5622 - val_loss: 0.0719 - val_accuracy: 0.5802 Epoch 7/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.5905 - val_loss: 0.0689 - val_accuracy: 0.6073 Epoch 8/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.6138 - val_loss: 0.0662 - val_accuracy: 0.6313 Epoch 9/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.6349 - val_loss: 0.0637 - val_accuracy: 0.6522 Epoch 10/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0634 - accuracy: 0.6527 - val_loss: 0.0616 - val_accuracy: 0.6674 Epoch 11/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.6697 - val_loss: 0.0596 - val_accuracy: 0.6828 Epoch 12/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.6840 - val_loss: 0.0579 - val_accuracy: 0.6962 Epoch 13/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.6981 - val_loss: 0.0563 - val_accuracy: 0.7090 Epoch 14/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.7113 - val_loss: 0.0548 - val_accuracy: 0.7237 Epoch 15/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 0.7253 - val_loss: 0.0535 - val_accuracy: 0.7368 Epoch 16/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.7365 - val_loss: 0.0523 - val_accuracy: 0.7493 Epoch 17/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.7491 - val_loss: 0.0512 - val_accuracy: 0.7624 Epoch 18/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.7612 - val_loss: 0.0501 - val_accuracy: 0.7737 Epoch 19/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.7709 - val_loss: 0.0491 - val_accuracy: 0.7858 Epoch 20/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.7811 - val_loss: 0.0482 - val_accuracy: 0.7955 Epoch 21/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.7893 - val_loss: 0.0473 - val_accuracy: 0.8022 Epoch 22/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.7966 - val_loss: 0.0465 - val_accuracy: 0.8090 Epoch 23/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0470 - accuracy: 0.8025 - val_loss: 0.0457 - val_accuracy: 0.8140 Epoch 24/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.8077 - val_loss: 0.0450 - val_accuracy: 0.8197 Epoch 25/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.8116 - val_loss: 0.0443 - val_accuracy: 0.8234 Epoch 26/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.8154 - val_loss: 0.0437 - val_accuracy: 0.8272 Epoch 27/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.8184 - val_loss: 0.0431 - val_accuracy: 0.8289 Epoch 28/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.8212 - val_loss: 0.0425 - val_accuracy: 0.8323 Epoch 29/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.8234 - val_loss: 0.0420 - val_accuracy: 0.8342 Epoch 30/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.8256 - val_loss: 0.0414 - val_accuracy: 0.8370 Epoch 31/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.8274 - val_loss: 0.0409 - val_accuracy: 0.8388 Epoch 32/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.8293 - val_loss: 0.0405 - val_accuracy: 0.8403 Epoch 33/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.8309 - val_loss: 0.0400 - val_accuracy: 0.8414 Epoch 34/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.8322 - val_loss: 0.0396 - val_accuracy: 0.8426 Epoch 35/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.8338 - val_loss: 0.0392 - val_accuracy: 0.8439 Epoch 36/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.8353 - val_loss: 0.0388 - val_accuracy: 0.8449 Epoch 37/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.8369 - val_loss: 0.0385 - val_accuracy: 0.8463 Epoch 38/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.8385 - val_loss: 0.0381 - val_accuracy: 0.8477 Epoch 39/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0388 - accuracy: 0.8395 - val_loss: 0.0378 - val_accuracy: 0.8484 Epoch 40/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.8402 - val_loss: 0.0374 - val_accuracy: 0.8490 Epoch 41/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.8413 - val_loss: 0.0371 - val_accuracy: 0.8500 Epoch 42/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.8420 - val_loss: 0.0368 - val_accuracy: 0.8507 Epoch 43/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.8427 - val_loss: 0.0365 - val_accuracy: 0.8524 Epoch 44/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.8438 - val_loss: 0.0363 - val_accuracy: 0.8534 Epoch 45/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.8448 - val_loss: 0.0360 - val_accuracy: 0.8545 Epoch 46/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.8458 - val_loss: 0.0357 - val_accuracy: 0.8551 Epoch 47/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.8464 - val_loss: 0.0355 - val_accuracy: 0.8559 Epoch 48/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.8471 - val_loss: 0.0353 - val_accuracy: 0.8562 Epoch 49/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.8479 - val_loss: 0.0350 - val_accuracy: 0.8572 Epoch 50/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.8484 - val_loss: 0.0348 - val_accuracy: 0.8578 Epoch 51/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.8490 - val_loss: 0.0346 - val_accuracy: 0.8583 Epoch 52/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.8497 - val_loss: 0.0344 - val_accuracy: 0.8587 Epoch 53/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.8504 - val_loss: 0.0342 - val_accuracy: 0.8593 Epoch 54/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.8510 - val_loss: 0.0340 - val_accuracy: 0.8595 Epoch 55/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.8516 - val_loss: 0.0338 - val_accuracy: 0.8604 Epoch 56/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.8522 - val_loss: 0.0336 - val_accuracy: 0.8605 Epoch 57/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.8526 - val_loss: 0.0334 - val_accuracy: 0.8608 Epoch 58/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.8531 - val_loss: 0.0332 - val_accuracy: 0.8611 Epoch 59/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.8536 - val_loss: 0.0331 - val_accuracy: 0.8617 Epoch 60/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.8540 - val_loss: 0.0329 - val_accuracy: 0.8619 Epoch 61/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.8547 - val_loss: 0.0327 - val_accuracy: 0.8621 Epoch 62/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.8549 - val_loss: 0.0326 - val_accuracy: 0.8627 Epoch 63/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.8553 - val_loss: 0.0324 - val_accuracy: 0.8635 Epoch 64/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.8556 - val_loss: 0.0323 - val_accuracy: 0.8637 Epoch 65/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.8562 - val_loss: 0.0321 - val_accuracy: 0.8634 Epoch 66/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.8563 - val_loss: 0.0320 - val_accuracy: 0.8636 Epoch 67/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.8565 - val_loss: 0.0319 - val_accuracy: 0.8642 Epoch 68/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.8572 - val_loss: 0.0317 - val_accuracy: 0.8648 Epoch 69/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.8575 - val_loss: 0.0316 - val_accuracy: 0.8653 Epoch 70/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.8577 - val_loss: 0.0315 - val_accuracy: 0.8660 Epoch 71/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.8582 - val_loss: 0.0313 - val_accuracy: 0.8662 Epoch 72/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.8586 - val_loss: 0.0312 - val_accuracy: 0.8663 Epoch 73/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.8590 - val_loss: 0.0311 - val_accuracy: 0.8668 Epoch 74/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.8594 - val_loss: 0.0310 - val_accuracy: 0.8674 Epoch 75/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.8598 - val_loss: 0.0309 - val_accuracy: 0.8676 Epoch 76/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.8602 - val_loss: 0.0307 - val_accuracy: 0.8679 Epoch 77/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.8605 - val_loss: 0.0306 - val_accuracy: 0.8688 Epoch 78/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.8609 - val_loss: 0.0305 - val_accuracy: 0.8696 Epoch 79/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.8613 - val_loss: 0.0304 - val_accuracy: 0.8702 Epoch 80/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.8618 - val_loss: 0.0303 - val_accuracy: 0.8707 Epoch 81/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.8622 - val_loss: 0.0302 - val_accuracy: 0.8713 Epoch 82/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.8623 - val_loss: 0.0301 - val_accuracy: 0.8719 Epoch 83/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.8626 - val_loss: 0.0300 - val_accuracy: 0.8723 Epoch 84/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.8631 - val_loss: 0.0299 - val_accuracy: 0.8728 Epoch 85/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.8635 - val_loss: 0.0298 - val_accuracy: 0.8730 Epoch 86/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.8638 - val_loss: 0.0297 - val_accuracy: 0.8730 Epoch 87/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.8641 - val_loss: 0.0296 - val_accuracy: 0.8733 Epoch 88/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.8645 - val_loss: 0.0295 - val_accuracy: 0.8736 Epoch 89/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.8646 - val_loss: 0.0294 - val_accuracy: 0.8738 Epoch 90/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.8650 - val_loss: 0.0294 - val_accuracy: 0.8743 Epoch 91/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.8651 - val_loss: 0.0293 - val_accuracy: 0.8745 Epoch 92/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.8655 - val_loss: 0.0292 - val_accuracy: 0.8746 Epoch 93/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.8657 - val_loss: 0.0291 - val_accuracy: 0.8749 Epoch 94/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.8660 - val_loss: 0.0290 - val_accuracy: 0.8748 Epoch 95/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.8663 - val_loss: 0.0289 - val_accuracy: 0.8752 Epoch 96/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.8666 - val_loss: 0.0289 - val_accuracy: 0.8754 Epoch 97/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.8668 - val_loss: 0.0288 - val_accuracy: 0.8756 Epoch 98/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.8673 - val_loss: 0.0287 - val_accuracy: 0.8759 Epoch 99/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.8675 - val_loss: 0.0286 - val_accuracy: 0.8762 Epoch 100/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.8676 - val_loss: 0.0286 - val_accuracy: 0.8766 Epoch 101/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.8678 - val_loss: 0.0285 - val_accuracy: 0.8769 Epoch 102/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.8681 - val_loss: 0.0284 - val_accuracy: 0.8771 Epoch 103/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.8683 - val_loss: 0.0283 - val_accuracy: 0.8775 Epoch 104/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.8684 - val_loss: 0.0283 - val_accuracy: 0.8776 Epoch 105/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.8687 - val_loss: 0.0282 - val_accuracy: 0.8778 Epoch 106/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.8689 - val_loss: 0.0281 - val_accuracy: 0.8780 Epoch 107/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.8691 - val_loss: 0.0281 - val_accuracy: 0.8780 Epoch 108/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.8694 - val_loss: 0.0280 - val_accuracy: 0.8786 Epoch 109/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.8695 - val_loss: 0.0279 - val_accuracy: 0.8787 Epoch 110/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.8697 - val_loss: 0.0279 - val_accuracy: 0.8789 Epoch 111/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.8698 - val_loss: 0.0278 - val_accuracy: 0.8790 Epoch 112/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.8700 - val_loss: 0.0278 - val_accuracy: 0.8795 Epoch 113/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.8701 - val_loss: 0.0277 - val_accuracy: 0.8795 Epoch 114/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.8703 - val_loss: 0.0276 - val_accuracy: 0.8795 Epoch 115/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.8702 - val_loss: 0.0276 - val_accuracy: 0.8796 Epoch 116/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.8704 - val_loss: 0.0275 - val_accuracy: 0.8798 Epoch 117/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.8706 - val_loss: 0.0275 - val_accuracy: 0.8800 Epoch 118/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.8708 - val_loss: 0.0274 - val_accuracy: 0.8801 Epoch 119/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.8709 - val_loss: 0.0273 - val_accuracy: 0.8805 Epoch 120/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.8712 - val_loss: 0.0273 - val_accuracy: 0.8806 Epoch 121/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.8713 - val_loss: 0.0272 - val_accuracy: 0.8809 Epoch 122/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.8716 - val_loss: 0.0272 - val_accuracy: 0.8810 Epoch 123/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.8719 - val_loss: 0.0271 - val_accuracy: 0.8814 Epoch 124/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.8720 - val_loss: 0.0271 - val_accuracy: 0.8815 Epoch 125/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.8723 - val_loss: 0.0270 - val_accuracy: 0.8818 Epoch 126/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.8725 - val_loss: 0.0270 - val_accuracy: 0.8818 Epoch 127/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.8727 - val_loss: 0.0269 - val_accuracy: 0.8819 Epoch 128/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.8728 - val_loss: 0.0269 - val_accuracy: 0.8819 Epoch 129/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.8733 - val_loss: 0.0268 - val_accuracy: 0.8820 Epoch 130/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.8733 - val_loss: 0.0268 - val_accuracy: 0.8820 Epoch 131/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.8735 - val_loss: 0.0267 - val_accuracy: 0.8821 Epoch 132/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.8736 - val_loss: 0.0267 - val_accuracy: 0.8825 Epoch 133/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.8737 - val_loss: 0.0266 - val_accuracy: 0.8826 Epoch 134/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.8740 - val_loss: 0.0266 - val_accuracy: 0.8826 Epoch 135/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.8741 - val_loss: 0.0265 - val_accuracy: 0.8830 Epoch 136/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.8742 - val_loss: 0.0265 - val_accuracy: 0.8830 Epoch 137/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.8744 - val_loss: 0.0264 - val_accuracy: 0.8834 Epoch 138/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.8745 - val_loss: 0.0264 - val_accuracy: 0.8837 Epoch 139/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.8747 - val_loss: 0.0263 - val_accuracy: 0.8836 Epoch 140/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.8748 - val_loss: 0.0263 - val_accuracy: 0.8839 Epoch 141/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.8751 - val_loss: 0.0263 - val_accuracy: 0.8842 Epoch 142/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.8751 - val_loss: 0.0262 - val_accuracy: 0.8843 Epoch 143/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.8752 - val_loss: 0.0262 - val_accuracy: 0.8844 Epoch 144/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.8753 - val_loss: 0.0261 - val_accuracy: 0.8844 Epoch 145/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.8754 - val_loss: 0.0261 - val_accuracy: 0.8843 Epoch 146/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.8755 - val_loss: 0.0260 - val_accuracy: 0.8843 Epoch 147/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.8757 - val_loss: 0.0260 - val_accuracy: 0.8844 Epoch 148/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.8758 - val_loss: 0.0260 - val_accuracy: 0.8844 Epoch 149/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.8759 - val_loss: 0.0259 - val_accuracy: 0.8847 Epoch 150/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.8760 - val_loss: 0.0259 - val_accuracy: 0.8849 . . Learning Curve . Para visualisar a etapa de terinamento, iremos mostrar a chamada Learning Curve, em português, curva de aprendizado. Ela consiste em mostrar o custo por época, bem como a taxa de acerto (acurácia) por época. . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist1.history[&#39;accuracy&#39;]), label=&#39;Treino&#39;) axes[0].plot(100 * np.array(hist1.history[&#39;val_accuracy&#39;]), label=&#39;Teste&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist1.history[&#39;loss&#39;]), label=&#39;Treino&#39;) axes[1].plot(100 * np.array(hist1.history[&#39;val_loss&#39;]), label=&#39;Teste&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7f32d2c30d30&gt; . Visualiza&#231;&#227;o do modelo . Podemos ter um olhar mais profundo sobre a rede neural ao visualisarmos seus pesos. Especialmente, nossa atenção será voltada para a matriz de pesos $W$. Note que $W$ é uma matriz $d times K$, onde $d$ é o número de características, e $K$ é o número de classes. . Podemos dizer que cada valor $W_{ij}$ dá a relevância de cada pixel $ij$ da matriz. Além disso, note que podemos dividir $W in mathbb{R}^{d times K}$, como $K$ vetores $d-$dimensionais, . $$ W = [W_{1}, cdots, W_{K}] $$Note ainda que como nós definimos $d = 28 times 28$, podemos re-transformar os pesos em uma imagem através do método $.reshape$. Isso nos permitirá uma visualização concreta das matrizes de peso. Atente que as zonas em vermelho mostram valores positivos, em azul mostram valores negativos, e próximos ao verde mostram valores próximos de zero. . W = model1.layers[1].weights[0].numpy() # b = model.layers[1].weights[1].numpy() fig, axes = plt.subplots(3, 3, figsize=(10, 10)) for i, ax in enumerate(axes.flatten()): ax.imshow(W[:, i].reshape(28, 28), cmap=&#39;jet&#39;) ax.set_xticks([]) ax.set_yticks([]) plt.savefig(&#39;single_layer_weights.pdf&#39;) . Há ainda muito ruído nos pesos da rede. Mas de maneira um pouco forçosa podemos dizer que cada peso corresponde à um &quot;protótipo&quot; de um dígito. Ou seja, cada neurônio se especializa no aprendizado de um único dígito. A próxima seção vai tratar da aprendizagem com regularização, que vai tornar esta última afirmação mais evidente. . Treinamento Perceptron Simples + Regulariza&#231;&#227;o . Regularização é uma técnica de combate ao overfitting, um fenômeno que acontece em modelos preditivos onde o modelo aprende &quot;bem demais&quot; os dados de treinamento: o modelo é tão complexo que consegue decorar os exemplos de entrada. Para novos dados, o modelo tem performance inferior. . Apesar de o exemplo anterior não demonstrar overfitting, sua matriz de pesos contém bastante ruído pois seus pesos não são limitados à um intervalo. Uma maneira de eliminar esse ruído e obter uma visualização melhor é através da regularização. Isso consiste em adiconar uma penalização à função de custo, . $$ mathcal{L}_{reg}( mathbf{W}, mathbf{b}) = mathcal{L}( mathbf{W}, mathbf{b}) + lambda Omega( mathbf{W}) $$Nessa prática iremos demonstrar o uso da penalidade $ ell^{2}$, definida através da fórmula, . $$ Omega( mathbf{W}) = dfrac{1}{2}|| mathbf{W}||^{2}_{2}, Omega( mathbf{W}) = dfrac{1}{2} sum_{i=1}^{d} sum_{j=1}^{K}W_{ij}^{2} $$Outros termos de regularização existem. Nós utilisaremos o termo $l2$ . def perceptron_mnist_l2_reg(input_shape=(784,), n_classes=10, penalty=1e-3): x = tf.keras.layers.Input(shape=input_shape) y = tf.keras.layers.Dense(units=n_classes, kernel_regularizer=tf.keras.regularizers.l2(penalty), activation=&#39;sigmoid&#39;)(x) return tf.keras.models.Model(x, y) . # Definição do modelo model2 = perceptron_mnist_l2_reg() # 1. Instanciação do custo loss_obj = tf.keras.losses.MeanSquaredError() # 2. Instanciação do otimizador optimizer_obj = tf.keras.optimizers.SGD(learning_rate=1e-1) # 3. Compilação do modelo model2.compile( loss=loss_obj, optimizer=optimizer_obj, metrics=[&#39;accuracy&#39;] ) # 4. Treinamento hist2 = model2.fit(x=Xtr, y=ytr, batch_size=1024, epochs=150, validation_data=(Xts, yts), validation_batch_size=128) . Epoch 1/150 59/59 [==============================] - 1s 9ms/step - loss: 0.1520 - accuracy: 0.1715 - val_loss: 0.1179 - val_accuracy: 0.2478 Epoch 2/150 59/59 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.3326 - val_loss: 0.1076 - val_accuracy: 0.3823 Epoch 3/150 59/59 [==============================] - 0s 7ms/step - loss: 0.1050 - accuracy: 0.4351 - val_loss: 0.1024 - val_accuracy: 0.4560 Epoch 4/150 59/59 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.4920 - val_loss: 0.0983 - val_accuracy: 0.5088 Epoch 5/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0965 - accuracy: 0.5349 - val_loss: 0.0946 - val_accuracy: 0.5496 Epoch 6/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.5712 - val_loss: 0.0913 - val_accuracy: 0.5851 Epoch 7/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.5995 - val_loss: 0.0883 - val_accuracy: 0.6128 Epoch 8/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.6232 - val_loss: 0.0856 - val_accuracy: 0.6335 Epoch 9/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.6414 - val_loss: 0.0832 - val_accuracy: 0.6510 Epoch 10/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.6583 - val_loss: 0.0810 - val_accuracy: 0.6679 Epoch 11/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.6723 - val_loss: 0.0791 - val_accuracy: 0.6819 Epoch 12/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.6857 - val_loss: 0.0774 - val_accuracy: 0.6956 Epoch 13/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.6976 - val_loss: 0.0758 - val_accuracy: 0.7049 Epoch 14/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0756 - accuracy: 0.7075 - val_loss: 0.0744 - val_accuracy: 0.7139 Epoch 15/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.7161 - val_loss: 0.0731 - val_accuracy: 0.7241 Epoch 16/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0731 - accuracy: 0.7248 - val_loss: 0.0720 - val_accuracy: 0.7342 Epoch 17/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 0.7330 - val_loss: 0.0709 - val_accuracy: 0.7429 Epoch 18/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.7421 - val_loss: 0.0699 - val_accuracy: 0.7498 Epoch 19/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.7509 - val_loss: 0.0689 - val_accuracy: 0.7598 Epoch 20/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.7590 - val_loss: 0.0681 - val_accuracy: 0.7666 Epoch 21/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.7665 - val_loss: 0.0672 - val_accuracy: 0.7731 Epoch 22/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.7745 - val_loss: 0.0665 - val_accuracy: 0.7804 Epoch 23/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.7810 - val_loss: 0.0657 - val_accuracy: 0.7884 Epoch 24/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.7881 - val_loss: 0.0650 - val_accuracy: 0.7955 Epoch 25/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.7935 - val_loss: 0.0644 - val_accuracy: 0.8016 Epoch 26/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0647 - accuracy: 0.7989 - val_loss: 0.0638 - val_accuracy: 0.8060 Epoch 27/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.8041 - val_loss: 0.0632 - val_accuracy: 0.8098 Epoch 28/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.8083 - val_loss: 0.0626 - val_accuracy: 0.8135 Epoch 29/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0630 - accuracy: 0.8118 - val_loss: 0.0620 - val_accuracy: 0.8177 Epoch 30/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.8149 - val_loss: 0.0615 - val_accuracy: 0.8203 Epoch 31/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.8179 - val_loss: 0.0610 - val_accuracy: 0.8233 Epoch 32/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0615 - accuracy: 0.8204 - val_loss: 0.0605 - val_accuracy: 0.8259 Epoch 33/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.8226 - val_loss: 0.0601 - val_accuracy: 0.8288 Epoch 34/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0606 - accuracy: 0.8249 - val_loss: 0.0597 - val_accuracy: 0.8307 Epoch 35/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.8264 - val_loss: 0.0592 - val_accuracy: 0.8327 Epoch 36/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0598 - accuracy: 0.8283 - val_loss: 0.0589 - val_accuracy: 0.8349 Epoch 37/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.8296 - val_loss: 0.0585 - val_accuracy: 0.8365 Epoch 38/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.8310 - val_loss: 0.0581 - val_accuracy: 0.8378 Epoch 39/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.8322 - val_loss: 0.0578 - val_accuracy: 0.8384 Epoch 40/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.8335 - val_loss: 0.0574 - val_accuracy: 0.8396 Epoch 41/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.8349 - val_loss: 0.0571 - val_accuracy: 0.8414 Epoch 42/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.8355 - val_loss: 0.0568 - val_accuracy: 0.8426 Epoch 43/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.8365 - val_loss: 0.0565 - val_accuracy: 0.8433 Epoch 44/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.8374 - val_loss: 0.0562 - val_accuracy: 0.8446 Epoch 45/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0569 - accuracy: 0.8385 - val_loss: 0.0560 - val_accuracy: 0.8458 Epoch 46/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.8392 - val_loss: 0.0557 - val_accuracy: 0.8462 Epoch 47/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0563 - accuracy: 0.8404 - val_loss: 0.0554 - val_accuracy: 0.8463 Epoch 48/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.8407 - val_loss: 0.0552 - val_accuracy: 0.8473 Epoch 49/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.8417 - val_loss: 0.0550 - val_accuracy: 0.8480 Epoch 50/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.8423 - val_loss: 0.0547 - val_accuracy: 0.8485 Epoch 51/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.8431 - val_loss: 0.0545 - val_accuracy: 0.8492 Epoch 52/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.8435 - val_loss: 0.0543 - val_accuracy: 0.8497 Epoch 53/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 0.8442 - val_loss: 0.0541 - val_accuracy: 0.8501 Epoch 54/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.8449 - val_loss: 0.0539 - val_accuracy: 0.8504 Epoch 55/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.8456 - val_loss: 0.0537 - val_accuracy: 0.8517 Epoch 56/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.8457 - val_loss: 0.0535 - val_accuracy: 0.8518 Epoch 57/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.8462 - val_loss: 0.0533 - val_accuracy: 0.8520 Epoch 58/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.8469 - val_loss: 0.0531 - val_accuracy: 0.8521 Epoch 59/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.8469 - val_loss: 0.0530 - val_accuracy: 0.8530 Epoch 60/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.8477 - val_loss: 0.0528 - val_accuracy: 0.8531 Epoch 61/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.8480 - val_loss: 0.0527 - val_accuracy: 0.8539 Epoch 62/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0534 - accuracy: 0.8483 - val_loss: 0.0525 - val_accuracy: 0.8543 Epoch 63/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.8487 - val_loss: 0.0523 - val_accuracy: 0.8549 Epoch 64/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0531 - accuracy: 0.8492 - val_loss: 0.0522 - val_accuracy: 0.8553 Epoch 65/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.8497 - val_loss: 0.0521 - val_accuracy: 0.8555 Epoch 66/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.8500 - val_loss: 0.0519 - val_accuracy: 0.8562 Epoch 67/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.8503 - val_loss: 0.0518 - val_accuracy: 0.8567 Epoch 68/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0525 - accuracy: 0.8510 - val_loss: 0.0516 - val_accuracy: 0.8570 Epoch 69/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.8512 - val_loss: 0.0515 - val_accuracy: 0.8576 Epoch 70/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.8517 - val_loss: 0.0514 - val_accuracy: 0.8576 Epoch 71/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.8519 - val_loss: 0.0513 - val_accuracy: 0.8581 Epoch 72/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.8523 - val_loss: 0.0512 - val_accuracy: 0.8586 Epoch 73/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.8524 - val_loss: 0.0510 - val_accuracy: 0.8591 Epoch 74/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.8528 - val_loss: 0.0509 - val_accuracy: 0.8597 Epoch 75/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.8533 - val_loss: 0.0508 - val_accuracy: 0.8599 Epoch 76/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.8536 - val_loss: 0.0507 - val_accuracy: 0.8607 Epoch 77/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.8538 - val_loss: 0.0506 - val_accuracy: 0.8609 Epoch 78/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.8541 - val_loss: 0.0505 - val_accuracy: 0.8612 Epoch 79/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.8544 - val_loss: 0.0504 - val_accuracy: 0.8610 Epoch 80/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.8547 - val_loss: 0.0503 - val_accuracy: 0.8615 Epoch 81/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.8549 - val_loss: 0.0502 - val_accuracy: 0.8624 Epoch 82/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.8551 - val_loss: 0.0501 - val_accuracy: 0.8625 Epoch 83/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.8554 - val_loss: 0.0500 - val_accuracy: 0.8625 Epoch 84/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.8558 - val_loss: 0.0500 - val_accuracy: 0.8628 Epoch 85/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.8558 - val_loss: 0.0499 - val_accuracy: 0.8632 Epoch 86/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.8561 - val_loss: 0.0498 - val_accuracy: 0.8634 Epoch 87/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.8563 - val_loss: 0.0497 - val_accuracy: 0.8636 Epoch 88/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.8565 - val_loss: 0.0496 - val_accuracy: 0.8640 Epoch 89/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.8568 - val_loss: 0.0495 - val_accuracy: 0.8645 Epoch 90/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.8570 - val_loss: 0.0495 - val_accuracy: 0.8649 Epoch 91/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.8575 - val_loss: 0.0494 - val_accuracy: 0.8649 Epoch 92/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.8576 - val_loss: 0.0493 - val_accuracy: 0.8650 Epoch 93/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.8575 - val_loss: 0.0493 - val_accuracy: 0.8653 Epoch 94/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.8577 - val_loss: 0.0492 - val_accuracy: 0.8658 Epoch 95/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.8580 - val_loss: 0.0491 - val_accuracy: 0.8662 Epoch 96/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.8585 - val_loss: 0.0491 - val_accuracy: 0.8665 Epoch 97/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.8587 - val_loss: 0.0490 - val_accuracy: 0.8661 Epoch 98/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.8589 - val_loss: 0.0489 - val_accuracy: 0.8662 Epoch 99/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.8587 - val_loss: 0.0489 - val_accuracy: 0.8666 Epoch 100/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.8590 - val_loss: 0.0488 - val_accuracy: 0.8669 Epoch 101/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.8595 - val_loss: 0.0487 - val_accuracy: 0.8669 Epoch 102/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.8595 - val_loss: 0.0487 - val_accuracy: 0.8672 Epoch 103/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.8597 - val_loss: 0.0486 - val_accuracy: 0.8674 Epoch 104/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.8600 - val_loss: 0.0486 - val_accuracy: 0.8677 Epoch 105/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.8602 - val_loss: 0.0485 - val_accuracy: 0.8679 Epoch 106/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.8603 - val_loss: 0.0485 - val_accuracy: 0.8680 Epoch 107/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.8605 - val_loss: 0.0484 - val_accuracy: 0.8680 Epoch 108/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.8604 - val_loss: 0.0484 - val_accuracy: 0.8686 Epoch 109/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.8608 - val_loss: 0.0483 - val_accuracy: 0.8685 Epoch 110/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.8609 - val_loss: 0.0483 - val_accuracy: 0.8688 Epoch 111/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.8609 - val_loss: 0.0482 - val_accuracy: 0.8691 Epoch 112/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.8611 - val_loss: 0.0482 - val_accuracy: 0.8694 Epoch 113/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.8613 - val_loss: 0.0481 - val_accuracy: 0.8694 Epoch 114/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.8612 - val_loss: 0.0481 - val_accuracy: 0.8695 Epoch 115/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.8615 - val_loss: 0.0480 - val_accuracy: 0.8697 Epoch 116/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.8615 - val_loss: 0.0480 - val_accuracy: 0.8697 Epoch 117/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.8618 - val_loss: 0.0479 - val_accuracy: 0.8697 Epoch 118/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.8617 - val_loss: 0.0479 - val_accuracy: 0.8700 Epoch 119/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.8619 - val_loss: 0.0479 - val_accuracy: 0.8701 Epoch 120/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.8620 - val_loss: 0.0478 - val_accuracy: 0.8704 Epoch 121/150 59/59 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 0.8621 - val_loss: 0.0478 - val_accuracy: 0.8704 Epoch 122/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.8620 - val_loss: 0.0477 - val_accuracy: 0.8709 Epoch 123/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.8623 - val_loss: 0.0477 - val_accuracy: 0.8709 Epoch 124/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.8624 - val_loss: 0.0477 - val_accuracy: 0.8709 Epoch 125/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.8624 - val_loss: 0.0476 - val_accuracy: 0.8710 Epoch 126/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.8625 - val_loss: 0.0476 - val_accuracy: 0.8712 Epoch 127/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.8626 - val_loss: 0.0476 - val_accuracy: 0.8711 Epoch 128/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.8629 - val_loss: 0.0475 - val_accuracy: 0.8713 Epoch 129/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.8629 - val_loss: 0.0475 - val_accuracy: 0.8714 Epoch 130/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.8628 - val_loss: 0.0474 - val_accuracy: 0.8714 Epoch 131/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.8631 - val_loss: 0.0474 - val_accuracy: 0.8715 Epoch 132/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.8632 - val_loss: 0.0474 - val_accuracy: 0.8718 Epoch 133/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.8631 - val_loss: 0.0474 - val_accuracy: 0.8718 Epoch 134/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.8632 - val_loss: 0.0473 - val_accuracy: 0.8720 Epoch 135/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.8633 - val_loss: 0.0473 - val_accuracy: 0.8719 Epoch 136/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.8634 - val_loss: 0.0473 - val_accuracy: 0.8721 Epoch 137/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.8635 - val_loss: 0.0472 - val_accuracy: 0.8724 Epoch 138/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.8635 - val_loss: 0.0472 - val_accuracy: 0.8725 Epoch 139/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.8638 - val_loss: 0.0472 - val_accuracy: 0.8728 Epoch 140/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.8638 - val_loss: 0.0471 - val_accuracy: 0.8728 Epoch 141/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.8638 - val_loss: 0.0471 - val_accuracy: 0.8728 Epoch 142/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.8639 - val_loss: 0.0471 - val_accuracy: 0.8730 Epoch 143/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.8641 - val_loss: 0.0471 - val_accuracy: 0.8732 Epoch 144/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.8641 - val_loss: 0.0470 - val_accuracy: 0.8734 Epoch 145/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.8642 - val_loss: 0.0470 - val_accuracy: 0.8734 Epoch 146/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.8642 - val_loss: 0.0470 - val_accuracy: 0.8734 Epoch 147/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.8645 - val_loss: 0.0470 - val_accuracy: 0.8737 Epoch 148/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.8645 - val_loss: 0.0469 - val_accuracy: 0.8738 Epoch 149/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.8646 - val_loss: 0.0469 - val_accuracy: 0.8740 Epoch 150/150 59/59 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.8646 - val_loss: 0.0469 - val_accuracy: 0.8740 . . Aqui, fica mais claro a afirmação anterior: cada neurônio se especializa no reconhecimento de um tipo específico de dígito. . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist2.history[&#39;accuracy&#39;]), label=&#39;Treino&#39;) axes[0].plot(100 * np.array(hist2.history[&#39;val_accuracy&#39;]), label=&#39;Teste&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist2.history[&#39;loss&#39;]), label=&#39;Treino&#39;) axes[1].plot(100 * np.array(hist2.history[&#39;val_loss&#39;]), label=&#39;Teste&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7f32d1fc7f60&gt; . W = model2.layers[1].weights[0].numpy() # b = model.layers[1].weights[1].numpy() fig, axes = plt.subplots(3, 3, figsize=(10, 10)) for i, ax in enumerate(axes.flatten()): ax.imshow(W[:, i].reshape(28, 28), cmap=&#39;jet&#39;) ax.set_xticks([]) ax.set_yticks([]) plt.savefig(&#39;single_layer_weights_reg.pdf&#39;) . Exerc&#237;cios . Substitua a definição da função de ativação de &#39;sigmoid&#39; para &#39;softmax&#39;. Quais as implicações práticas? O que acontece com o treinamento? | Tente substituir a função de custo. Troque &#39;MeanSquaredError&#39; pela &#39;CategoricalCrossEntropy&#39; (por que não &#39;BinaryCrossEntropy&#39;?). Avalie os resultados obtidos. | Perceptron V&#225;rias Camadas . def mlp_mnist(input_shape=(784,), n_classes=10, penalty=1e-3): x = tf.keras.layers.Input(shape=input_shape) y = tf.keras.layers.Dense(units=196, activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(penalty))(x) y = tf.keras.layers.Dense(units=49, activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(penalty))(y) y = tf.keras.layers.Dense(units=n_classes, activation=&#39;softmax&#39;, kernel_regularizer=tf.keras.regularizers.l2(penalty))(y) return tf.keras.models.Model(x, y) . model3 = mlp_mnist() # Print do modelo construído model3.summary() . Model: &#34;functional_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_2 (Dense) (None, 196) 153860 _________________________________________________________________ dense_3 (Dense) (None, 49) 9653 _________________________________________________________________ dense_4 (Dense) (None, 10) 500 ================================================================= Total params: 164,013 Trainable params: 164,013 Non-trainable params: 0 _________________________________________________________________ . # Passo à passo: # 1. Instancie a função de custo (num primeiro momento, use MeanSquaredError) # 2. Instancie o otimizador (SGD, ou Stochastic Gradient Descent) # 3. Compile o modelo. # 1. Instanciação do custo loss_obj = tf.keras.losses.MeanSquaredError() # 2. Instanciação do otimizador optimizer_obj = tf.keras.optimizers.SGD(learning_rate=1e-1) # 3. Compilação do modelo model3.compile( loss=loss_obj, optimizer=optimizer_obj, metrics=[&#39;accuracy&#39;] ) . hist3 = model3.fit(x=Xtr, y=ytr, batch_size=1024, epochs=150, validation_data=(Xts, yts), validation_batch_size=128) . Epoch 1/150 59/59 [==============================] - 2s 26ms/step - loss: 0.4952 - accuracy: 0.1197 - val_loss: 0.4894 - val_accuracy: 0.1482 Epoch 2/150 59/59 [==============================] - 1s 21ms/step - loss: 0.4840 - accuracy: 0.1986 - val_loss: 0.4784 - val_accuracy: 0.2632 Epoch 3/150 59/59 [==============================] - 1s 22ms/step - loss: 0.4731 - accuracy: 0.3024 - val_loss: 0.4675 - val_accuracy: 0.3404 Epoch 4/150 59/59 [==============================] - 1s 22ms/step - loss: 0.4622 - accuracy: 0.3571 - val_loss: 0.4565 - val_accuracy: 0.3814 Epoch 5/150 59/59 [==============================] - 1s 23ms/step - loss: 0.4512 - accuracy: 0.3882 - val_loss: 0.4455 - val_accuracy: 0.4091 Epoch 6/150 59/59 [==============================] - 1s 22ms/step - loss: 0.4403 - accuracy: 0.4164 - val_loss: 0.4347 - val_accuracy: 0.4351 Epoch 7/150 59/59 [==============================] - 1s 22ms/step - loss: 0.4296 - accuracy: 0.4446 - val_loss: 0.4242 - val_accuracy: 0.4590 Epoch 8/150 59/59 [==============================] - 1s 21ms/step - loss: 0.4192 - accuracy: 0.4691 - val_loss: 0.4138 - val_accuracy: 0.4792 Epoch 9/150 59/59 [==============================] - 1s 21ms/step - loss: 0.4090 - accuracy: 0.4886 - val_loss: 0.4036 - val_accuracy: 0.4965 Epoch 10/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3990 - accuracy: 0.5055 - val_loss: 0.3938 - val_accuracy: 0.5135 Epoch 11/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3893 - accuracy: 0.5271 - val_loss: 0.3841 - val_accuracy: 0.5397 Epoch 12/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3799 - accuracy: 0.5558 - val_loss: 0.3748 - val_accuracy: 0.5697 Epoch 13/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3708 - accuracy: 0.5899 - val_loss: 0.3657 - val_accuracy: 0.6048 Epoch 14/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3619 - accuracy: 0.6228 - val_loss: 0.3569 - val_accuracy: 0.6394 Epoch 15/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3532 - accuracy: 0.6535 - val_loss: 0.3482 - val_accuracy: 0.6675 Epoch 16/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3447 - accuracy: 0.6791 - val_loss: 0.3398 - val_accuracy: 0.6926 Epoch 17/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3364 - accuracy: 0.7030 - val_loss: 0.3317 - val_accuracy: 0.7151 Epoch 18/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3285 - accuracy: 0.7243 - val_loss: 0.3238 - val_accuracy: 0.7354 Epoch 19/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3207 - accuracy: 0.7405 - val_loss: 0.3162 - val_accuracy: 0.7479 Epoch 20/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3133 - accuracy: 0.7523 - val_loss: 0.3089 - val_accuracy: 0.7607 Epoch 21/150 59/59 [==============================] - 1s 21ms/step - loss: 0.3062 - accuracy: 0.7615 - val_loss: 0.3019 - val_accuracy: 0.7716 Epoch 22/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2994 - accuracy: 0.7695 - val_loss: 0.2952 - val_accuracy: 0.7790 Epoch 23/150 59/59 [==============================] - 1s 22ms/step - loss: 0.2928 - accuracy: 0.7758 - val_loss: 0.2888 - val_accuracy: 0.7851 Epoch 24/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2864 - accuracy: 0.7815 - val_loss: 0.2825 - val_accuracy: 0.7905 Epoch 25/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2802 - accuracy: 0.7861 - val_loss: 0.2764 - val_accuracy: 0.7955 Epoch 26/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2743 - accuracy: 0.7943 - val_loss: 0.2705 - val_accuracy: 0.8047 Epoch 27/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2685 - accuracy: 0.8060 - val_loss: 0.2648 - val_accuracy: 0.8159 Epoch 28/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2629 - accuracy: 0.8163 - val_loss: 0.2593 - val_accuracy: 0.8259 Epoch 29/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2575 - accuracy: 0.8238 - val_loss: 0.2540 - val_accuracy: 0.8362 Epoch 30/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2523 - accuracy: 0.8324 - val_loss: 0.2489 - val_accuracy: 0.8416 Epoch 31/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2473 - accuracy: 0.8374 - val_loss: 0.2439 - val_accuracy: 0.8482 Epoch 32/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2424 - accuracy: 0.8426 - val_loss: 0.2391 - val_accuracy: 0.8525 Epoch 33/150 59/59 [==============================] - 1s 22ms/step - loss: 0.2377 - accuracy: 0.8469 - val_loss: 0.2345 - val_accuracy: 0.8555 Epoch 34/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2331 - accuracy: 0.8502 - val_loss: 0.2299 - val_accuracy: 0.8593 Epoch 35/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2286 - accuracy: 0.8531 - val_loss: 0.2255 - val_accuracy: 0.8625 Epoch 36/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2243 - accuracy: 0.8558 - val_loss: 0.2213 - val_accuracy: 0.8655 Epoch 37/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2201 - accuracy: 0.8581 - val_loss: 0.2171 - val_accuracy: 0.8670 Epoch 38/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2161 - accuracy: 0.8608 - val_loss: 0.2131 - val_accuracy: 0.8682 Epoch 39/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2121 - accuracy: 0.8630 - val_loss: 0.2092 - val_accuracy: 0.8700 Epoch 40/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2082 - accuracy: 0.8643 - val_loss: 0.2054 - val_accuracy: 0.8719 Epoch 41/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2045 - accuracy: 0.8660 - val_loss: 0.2017 - val_accuracy: 0.8735 Epoch 42/150 59/59 [==============================] - 1s 21ms/step - loss: 0.2008 - accuracy: 0.8674 - val_loss: 0.1981 - val_accuracy: 0.8745 Epoch 43/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1973 - accuracy: 0.8686 - val_loss: 0.1946 - val_accuracy: 0.8751 Epoch 44/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1938 - accuracy: 0.8700 - val_loss: 0.1912 - val_accuracy: 0.8766 Epoch 45/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1904 - accuracy: 0.8708 - val_loss: 0.1878 - val_accuracy: 0.8780 Epoch 46/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1872 - accuracy: 0.8723 - val_loss: 0.1846 - val_accuracy: 0.8788 Epoch 47/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1839 - accuracy: 0.8732 - val_loss: 0.1814 - val_accuracy: 0.8796 Epoch 48/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1808 - accuracy: 0.8741 - val_loss: 0.1783 - val_accuracy: 0.8802 Epoch 49/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1778 - accuracy: 0.8748 - val_loss: 0.1753 - val_accuracy: 0.8809 Epoch 50/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1748 - accuracy: 0.8755 - val_loss: 0.1724 - val_accuracy: 0.8810 Epoch 51/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1719 - accuracy: 0.8759 - val_loss: 0.1695 - val_accuracy: 0.8815 Epoch 52/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1691 - accuracy: 0.8767 - val_loss: 0.1667 - val_accuracy: 0.8820 Epoch 53/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1663 - accuracy: 0.8773 - val_loss: 0.1640 - val_accuracy: 0.8827 Epoch 54/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1637 - accuracy: 0.8780 - val_loss: 0.1614 - val_accuracy: 0.8828 Epoch 55/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1610 - accuracy: 0.8783 - val_loss: 0.1588 - val_accuracy: 0.8839 Epoch 56/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1585 - accuracy: 0.8786 - val_loss: 0.1563 - val_accuracy: 0.8846 Epoch 57/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1560 - accuracy: 0.8794 - val_loss: 0.1538 - val_accuracy: 0.8850 Epoch 58/150 59/59 [==============================] - 1s 23ms/step - loss: 0.1536 - accuracy: 0.8798 - val_loss: 0.1514 - val_accuracy: 0.8854 Epoch 59/150 59/59 [==============================] - 1s 23ms/step - loss: 0.1512 - accuracy: 0.8803 - val_loss: 0.1490 - val_accuracy: 0.8856 Epoch 60/150 59/59 [==============================] - 1s 23ms/step - loss: 0.1489 - accuracy: 0.8809 - val_loss: 0.1468 - val_accuracy: 0.8863 Epoch 61/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1466 - accuracy: 0.8811 - val_loss: 0.1445 - val_accuracy: 0.8864 Epoch 62/150 59/59 [==============================] - 1s 23ms/step - loss: 0.1444 - accuracy: 0.8814 - val_loss: 0.1423 - val_accuracy: 0.8874 Epoch 63/150 59/59 [==============================] - 1s 23ms/step - loss: 0.1422 - accuracy: 0.8820 - val_loss: 0.1402 - val_accuracy: 0.8869 Epoch 64/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1401 - accuracy: 0.8821 - val_loss: 0.1381 - val_accuracy: 0.8880 Epoch 65/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1381 - accuracy: 0.8825 - val_loss: 0.1361 - val_accuracy: 0.8878 Epoch 66/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1361 - accuracy: 0.8826 - val_loss: 0.1342 - val_accuracy: 0.8879 Epoch 67/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1341 - accuracy: 0.8829 - val_loss: 0.1322 - val_accuracy: 0.8881 Epoch 68/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1322 - accuracy: 0.8835 - val_loss: 0.1303 - val_accuracy: 0.8888 Epoch 69/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1304 - accuracy: 0.8835 - val_loss: 0.1285 - val_accuracy: 0.8889 Epoch 70/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1285 - accuracy: 0.8841 - val_loss: 0.1267 - val_accuracy: 0.8892 Epoch 71/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1268 - accuracy: 0.8841 - val_loss: 0.1249 - val_accuracy: 0.8890 Epoch 72/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1250 - accuracy: 0.8845 - val_loss: 0.1232 - val_accuracy: 0.8887 Epoch 73/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1233 - accuracy: 0.8849 - val_loss: 0.1216 - val_accuracy: 0.8893 Epoch 74/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1217 - accuracy: 0.8850 - val_loss: 0.1199 - val_accuracy: 0.8896 Epoch 75/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1201 - accuracy: 0.8853 - val_loss: 0.1183 - val_accuracy: 0.8900 Epoch 76/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1185 - accuracy: 0.8857 - val_loss: 0.1168 - val_accuracy: 0.8900 Epoch 77/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1170 - accuracy: 0.8859 - val_loss: 0.1153 - val_accuracy: 0.8899 Epoch 78/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1155 - accuracy: 0.8860 - val_loss: 0.1138 - val_accuracy: 0.8901 Epoch 79/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1140 - accuracy: 0.8860 - val_loss: 0.1123 - val_accuracy: 0.8903 Epoch 80/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1126 - accuracy: 0.8866 - val_loss: 0.1109 - val_accuracy: 0.8906 Epoch 81/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1112 - accuracy: 0.8866 - val_loss: 0.1096 - val_accuracy: 0.8904 Epoch 82/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1098 - accuracy: 0.8866 - val_loss: 0.1082 - val_accuracy: 0.8903 Epoch 83/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1085 - accuracy: 0.8868 - val_loss: 0.1069 - val_accuracy: 0.8907 Epoch 84/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1072 - accuracy: 0.8871 - val_loss: 0.1056 - val_accuracy: 0.8907 Epoch 85/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1059 - accuracy: 0.8871 - val_loss: 0.1044 - val_accuracy: 0.8913 Epoch 86/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1047 - accuracy: 0.8877 - val_loss: 0.1031 - val_accuracy: 0.8921 Epoch 87/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1035 - accuracy: 0.8877 - val_loss: 0.1019 - val_accuracy: 0.8913 Epoch 88/150 59/59 [==============================] - 1s 21ms/step - loss: 0.1023 - accuracy: 0.8877 - val_loss: 0.1008 - val_accuracy: 0.8923 Epoch 89/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1011 - accuracy: 0.8879 - val_loss: 0.0996 - val_accuracy: 0.8919 Epoch 90/150 59/59 [==============================] - 1s 22ms/step - loss: 0.1000 - accuracy: 0.8883 - val_loss: 0.0985 - val_accuracy: 0.8925 Epoch 91/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0989 - accuracy: 0.8880 - val_loss: 0.0974 - val_accuracy: 0.8927 Epoch 92/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0978 - accuracy: 0.8882 - val_loss: 0.0964 - val_accuracy: 0.8928 Epoch 93/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0968 - accuracy: 0.8884 - val_loss: 0.0953 - val_accuracy: 0.8930 Epoch 94/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0957 - accuracy: 0.8884 - val_loss: 0.0943 - val_accuracy: 0.8928 Epoch 95/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0947 - accuracy: 0.8886 - val_loss: 0.0933 - val_accuracy: 0.8929 Epoch 96/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0938 - accuracy: 0.8887 - val_loss: 0.0924 - val_accuracy: 0.8933 Epoch 97/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0928 - accuracy: 0.8888 - val_loss: 0.0914 - val_accuracy: 0.8935 Epoch 98/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0919 - accuracy: 0.8889 - val_loss: 0.0905 - val_accuracy: 0.8931 Epoch 99/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0910 - accuracy: 0.8888 - val_loss: 0.0896 - val_accuracy: 0.8935 Epoch 100/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0901 - accuracy: 0.8888 - val_loss: 0.0887 - val_accuracy: 0.8927 Epoch 101/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0892 - accuracy: 0.8888 - val_loss: 0.0879 - val_accuracy: 0.8940 Epoch 102/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0884 - accuracy: 0.8889 - val_loss: 0.0870 - val_accuracy: 0.8934 Epoch 103/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0875 - accuracy: 0.8893 - val_loss: 0.0862 - val_accuracy: 0.8938 Epoch 104/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0867 - accuracy: 0.8893 - val_loss: 0.0854 - val_accuracy: 0.8940 Epoch 105/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0859 - accuracy: 0.8894 - val_loss: 0.0847 - val_accuracy: 0.8940 Epoch 106/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0852 - accuracy: 0.8894 - val_loss: 0.0839 - val_accuracy: 0.8939 Epoch 107/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0844 - accuracy: 0.8896 - val_loss: 0.0831 - val_accuracy: 0.8936 Epoch 108/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0837 - accuracy: 0.8898 - val_loss: 0.0824 - val_accuracy: 0.8940 Epoch 109/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0830 - accuracy: 0.8896 - val_loss: 0.0817 - val_accuracy: 0.8944 Epoch 110/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0823 - accuracy: 0.8899 - val_loss: 0.0810 - val_accuracy: 0.8944 Epoch 111/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0816 - accuracy: 0.8899 - val_loss: 0.0803 - val_accuracy: 0.8940 Epoch 112/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0809 - accuracy: 0.8899 - val_loss: 0.0797 - val_accuracy: 0.8938 Epoch 113/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0802 - accuracy: 0.8898 - val_loss: 0.0790 - val_accuracy: 0.8942 Epoch 114/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0796 - accuracy: 0.8901 - val_loss: 0.0784 - val_accuracy: 0.8941 Epoch 115/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0790 - accuracy: 0.8902 - val_loss: 0.0778 - val_accuracy: 0.8942 Epoch 116/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0784 - accuracy: 0.8901 - val_loss: 0.0772 - val_accuracy: 0.8936 Epoch 117/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0778 - accuracy: 0.8902 - val_loss: 0.0766 - val_accuracy: 0.8942 Epoch 118/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0772 - accuracy: 0.8902 - val_loss: 0.0760 - val_accuracy: 0.8943 Epoch 119/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0766 - accuracy: 0.8905 - val_loss: 0.0754 - val_accuracy: 0.8941 Epoch 120/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0761 - accuracy: 0.8903 - val_loss: 0.0749 - val_accuracy: 0.8940 Epoch 121/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0755 - accuracy: 0.8906 - val_loss: 0.0744 - val_accuracy: 0.8947 Epoch 122/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0750 - accuracy: 0.8906 - val_loss: 0.0738 - val_accuracy: 0.8934 Epoch 123/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0745 - accuracy: 0.8904 - val_loss: 0.0733 - val_accuracy: 0.8944 Epoch 124/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0740 - accuracy: 0.8910 - val_loss: 0.0728 - val_accuracy: 0.8948 Epoch 125/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0735 - accuracy: 0.8908 - val_loss: 0.0723 - val_accuracy: 0.8936 Epoch 126/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0730 - accuracy: 0.8906 - val_loss: 0.0719 - val_accuracy: 0.8944 Epoch 127/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0725 - accuracy: 0.8909 - val_loss: 0.0714 - val_accuracy: 0.8938 Epoch 128/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0721 - accuracy: 0.8911 - val_loss: 0.0709 - val_accuracy: 0.8943 Epoch 129/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0716 - accuracy: 0.8910 - val_loss: 0.0705 - val_accuracy: 0.8941 Epoch 130/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0712 - accuracy: 0.8909 - val_loss: 0.0701 - val_accuracy: 0.8945 Epoch 131/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0707 - accuracy: 0.8912 - val_loss: 0.0696 - val_accuracy: 0.8936 Epoch 132/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0703 - accuracy: 0.8913 - val_loss: 0.0692 - val_accuracy: 0.8938 Epoch 133/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0699 - accuracy: 0.8914 - val_loss: 0.0688 - val_accuracy: 0.8938 Epoch 134/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0695 - accuracy: 0.8910 - val_loss: 0.0684 - val_accuracy: 0.8944 Epoch 135/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0691 - accuracy: 0.8914 - val_loss: 0.0680 - val_accuracy: 0.8945 Epoch 136/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0687 - accuracy: 0.8912 - val_loss: 0.0677 - val_accuracy: 0.8947 Epoch 137/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0684 - accuracy: 0.8914 - val_loss: 0.0673 - val_accuracy: 0.8946 Epoch 138/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0680 - accuracy: 0.8911 - val_loss: 0.0669 - val_accuracy: 0.8945 Epoch 139/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0676 - accuracy: 0.8914 - val_loss: 0.0666 - val_accuracy: 0.8939 Epoch 140/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0673 - accuracy: 0.8913 - val_loss: 0.0662 - val_accuracy: 0.8943 Epoch 141/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0669 - accuracy: 0.8916 - val_loss: 0.0659 - val_accuracy: 0.8942 Epoch 142/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0666 - accuracy: 0.8910 - val_loss: 0.0656 - val_accuracy: 0.8947 Epoch 143/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.8912 - val_loss: 0.0652 - val_accuracy: 0.8944 Epoch 144/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0660 - accuracy: 0.8911 - val_loss: 0.0649 - val_accuracy: 0.8944 Epoch 145/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0657 - accuracy: 0.8913 - val_loss: 0.0646 - val_accuracy: 0.8950 Epoch 146/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0654 - accuracy: 0.8914 - val_loss: 0.0643 - val_accuracy: 0.8945 Epoch 147/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0651 - accuracy: 0.8912 - val_loss: 0.0640 - val_accuracy: 0.8946 Epoch 148/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0648 - accuracy: 0.8914 - val_loss: 0.0638 - val_accuracy: 0.8949 Epoch 149/150 59/59 [==============================] - 1s 22ms/step - loss: 0.0645 - accuracy: 0.8915 - val_loss: 0.0635 - val_accuracy: 0.8950 Epoch 150/150 59/59 [==============================] - 1s 21ms/step - loss: 0.0642 - accuracy: 0.8917 - val_loss: 0.0632 - val_accuracy: 0.8948 . . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist3.history[&#39;accuracy&#39;]), label=&#39;Treino&#39;) axes[0].plot(100 * np.array(hist3.history[&#39;val_accuracy&#39;]), label=&#39;Teste&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist3.history[&#39;loss&#39;]), label=&#39;Treino&#39;) axes[1].plot(100 * np.array(hist3.history[&#39;val_loss&#39;]), label=&#39;Teste&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7f32d3c82198&gt; . fig, axes = plt.subplots(14, 14, figsize=(16, 16)) for k, ax in enumerate(axes.flatten()): w = model3.layers[1].weights[0].numpy() ax.imshow(w[:, k].reshape(28, 28), cmap=&#39;jet&#39;) ax.set_xticks([]) ax.set_yticks([]) plt.savefig(&#39;mlp_weights.pdf&#39;) . fig, axes = plt.subplots(7, 7, figsize=(16, 16)) for k, ax in enumerate(axes.flatten()): w = model3.layers[2].weights[0].numpy() ax.imshow(w[:, k].reshape(14, 14), cmap=&#39;jet&#39;) ax.set_xticks([]) ax.set_yticks([]) . O resultado anterior mostra que os neurônios continuam especializados na primeira camada oculta. Isso mostra uma limitação fundamental das redes neurais rasas: o seu conhecimento é concentrado. Especialmente, se a engenharia de características não é boa, os resultados adquiridos também não são satisfatórios. Essas limitações serão superadas ao utilisarmos modelos convolucionais. . Exerc&#237;cios . Teste os resultados anteriores utilisando outros números de camadas, outras funções de ativação, outros parâmetros de regularização. Qual a taxa de acerto máxima obtida para o conjunto de teste? . Comparando diferentes modelos . Para podermos comparar modelos diferentes, precisamos ser criteriosos no treinamento destes. Note que o desempenho de um modelo nas épocas iniciais é muito diferente do desempenho após convergência. Portanto, precisamos assegurar o seguinte: . Que o modelo convergiu, | Caso a convergência não seja assegurada para os diferentes modelos, fixa-se o batch_size e o número de épocas. | Note que os dois pontos são assegurados para os nossos experimentos. . Compara&#231;&#227;o durante treino . fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].plot(100 * np.array(hist1.history[&#39;accuracy&#39;]), label=&#39;Uma Camada&#39;) axes[0].plot(100 * np.array(hist2.history[&#39;accuracy&#39;]), label=&#39;Uma Camada (regularizado)&#39;) axes[0].plot(100 * np.array(hist3.history[&#39;accuracy&#39;]), label=&#39;Várias Camadas&#39;) axes[0].set_ylabel(&#39;Percentual de Acerto&#39;) axes[0].set_xlabel(&#39;Época&#39;) axes[0].legend() axes[1].plot(100 * np.array(hist1.history[&#39;loss&#39;]), label=&#39;Uma Camada&#39;) axes[1].plot(100 * np.array(hist2.history[&#39;loss&#39;]), label=&#39;Uma Camada (regularizado)&#39;) axes[1].plot(100 * np.array(hist3.history[&#39;loss&#39;]), label=&#39;Várias Camadas&#39;) axes[1].set_ylabel(&#39;Função de Erro&#39;) axes[1].set_xlabel(&#39;Época&#39;) axes[1].legend() . &lt;matplotlib.legend.Legend at 0x7f32cfbc42e8&gt; . Compara&#231;&#227;o dados de teste . yp1 = model1(Xts).numpy().argmax(axis=1) yp2 = model2(Xts).numpy().argmax(axis=1) yp3 = model3(Xts).numpy().argmax(axis=1) . print(&quot;Taxa de precisão (Uma Camada): {}&quot;.format(100 * accuracy_score(y_test, yp1))) print(&quot;Taxa de precisão (Uma Camada, regularizado): {}&quot;.format(100 * accuracy_score(y_test, yp2))) print(&quot;Taxa de precisão (Várias Camadas): {}&quot;.format(100 * accuracy_score(y_test, yp3))) . Taxa de precisão (Uma Camada): 88.49000000000001 Taxa de precisão (Uma Camada, regularizado): 87.4 Taxa de precisão (Várias Camadas): 89.48 .",
            "url": "https://eddardd.github.io/my-personal-blog/deep%20learning/tensorflow/image%20classification/neural%20networks/2020/12/01/Deep-Learning-com-Tensorflow-Aula1.html",
            "relUrl": "/deep%20learning/tensorflow/image%20classification/neural%20networks/2020/12/01/Deep-Learning-com-Tensorflow-Aula1.html",
            "date": " • Dec 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://eddardd.github.io/my-personal-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "",
          "content": "Education . . Bachelor&#39;s Degree in Electronic Engineering and Industrial Informatics | September/2018 - August/2020 | . Institut National des Sciences Appliquées de Rennes, Rennes, France | GPA: 17.26/20.00 | . Thesis Title: Optimal Transport for Domain Adaptation with Applications to Bacteria Stain Classification Advisor: Fred-Maurice Ngolè Mboula . Bachelor&#39;s Degree in Computer Engineering | January/2015 - April/2021 | . Universidade Federal do Ceará, Fortaleza, Brazil | GPA: 8.95/10.00 | . Thesis Title: Cross-Domain Fault Diagnosis through Optimal Transport Advisor: Michela Mulas . Professional Experience . . Dell Lead, Fortaleza, Brazil . Scientific Researcher in Data Mining | April 2021 - Present | . Responsible for mining textual data and creating data visualizations. . Comissariat pour l’Énergie Atomique et aux Énergies Alternatives, Giff-Sur-Yvette, France . Research Intern in Artificial Intelligence | March 2020 - August 2020 | . During this internship I was in charge of implementing Optimal Transport for Domain Adaptation methods for a problem involving transfer learning on the classification of bacteria cell stain. Supervisor: Fred-Maurice Ngolè Mboula . Institut d’Electronique et des Technologies du Numérique, groupe VAADER, Rennes, France . Research Intern in Deep Learning | March 2020 - August 2020 | . During this internship I was responsible for implementing a benchmark for comparing image denoising methods. A special focus was given to deep neural network methods. The benchmark is Open Source, and its code is hosted on Github Supervisor: Florian Lemarchand . Programming Skills . . Programming Languages . Python, Matlab (+++) C++/C (++) Javascript, VHDL (+) . Toolboxes and Libraries . Python: Tensorflow (+++), Python Optimal Transport (+++), Pytorch (++) Matlab: Simulink (++), Deep Learning Toolbos (++) . Other Software . Others: Tableau, Latex, HTML . Languages . . Portuguese (Mother Tongue) English (B2/Advanced) French (B2/Advanced) . Publications . . Lemarchand, F., Montesuma, E. F., Pelcat, M., &amp; Nogues, E. (2020, May). OpenDenoising: an Extensible Benchmark for Building Comparative Studies of Image Denoisers. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2648-2652). IEEE. [Bibtex] [Arxiv] [Code] | Montesuma, Eduardo F., Levi PSA Alencar, and Guilherme A. Barreto. Avaliação de Algoritmos de Classificação de Padrões na Detecção de Câncer do Colo do Útero. [Bibtex] [Paper] | Montesuma, E. F., &amp; Mboula, F. M. N. (2021, June). Wasserstein Barycenter Transport for Acoustic Adaptation. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3405-3409). [IEEE Explore] [Code] | Montesuma, E., &amp; Mboula, F. (2021). Wasserstein Barycenter for Multi-Source Domain Adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 16785-16793). [The CVF Open Access] [Paper] [Supplementary] [Code] | Scholarships and Awards . . From September/2018 to Ferbuary/2020 I had the opportunity to have my double degree studies in France funded by Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES), with a BRAFITEC Scolarship .",
          "url": "https://eddardd.github.io/my-personal-blog/cv/",
          "relUrl": "/cv/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Publications",
          "content": "A summary of my recent work is available at Google Scholar. . Thesis . 2021 . Montesuma, E. F. (2021, April). Cross-Domain Fault Diagnosis through Optimal Transport [Bachelor Thesis, Universidade Federal do Ceará]. [Research Gate] [Code] [Bibtex] . Conference Papers . 2021 . Montesuma, E. F., &amp; Mboula, F. M. N. (2021, June). Wasserstein Barycenter Transport for Acoustic Adaptation. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3405-3409). [IEEE Explore] [Code] [Bibtex] . Montesuma, E., &amp; Mboula, F. (2021). Wasserstein Barycenter for Multi-Source Domain Adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 16785-16793). [The CVF Open Access] [Paper] [Supplementary] [Code] [Bibtex] . 2020 . Lemarchand, F., Montesuma, E. F., Pelcat, M., &amp; Nogues, E. (2020, May). OpenDenoising: an Extensible Benchmark for Building Comparative Studies of Image Denoisers. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2648-2652). IEEE. [Arxiv] [Code] [Bibtex] . 2017 . Montesuma, E., Alencar, L., &amp; Barreto, G. (2017). Avaliação de Algoritmos de Classificação de Padrões na Detecção de Câncer do Colo do Útero. In VIII Simpósio de Instrumentação e Imagens Médicas (SIIM) / VII Simpósio de Processamento de Sinais (SPS). [Paper] [Bibtex] .",
          "url": "https://eddardd.github.io/my-personal-blog/publications/",
          "relUrl": "/publications/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
      ,"page8": {
          "title": "Talks and presentations",
          "content": "Lecture on Introductory Optimal Transport for Machine Learning (05/03/2020) . A link to the presentation slides may be found here. The code used for the figures and examples can be found here . Semana da Tecnologia da Informação e Comunicação 2020 (02/12/2020 and 03/12/2020) . Crash course on Deep Learning using Tensorflow (Portuguese) [Presentation] . Session 1: [Talk] [Practical Work] | Session 2: [Talk] [Practical Work] |",
          "url": "https://eddardd.github.io/my-personal-blog/talks/",
          "relUrl": "/talks/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://eddardd.github.io/my-personal-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}